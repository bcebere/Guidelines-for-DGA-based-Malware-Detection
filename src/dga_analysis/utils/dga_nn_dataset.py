# third party
import numpy as np
import torch
from torch.utils.data import Dataset
from transformers import BertTokenizer


def tokenize_data(X: np.ndarray, max_length: int, tokenizer=None):
    if tokenizer is None:
        tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

    tokens = tokenizer(
        X,
        padding="max_length",
        truncation=True,
        return_tensors="pt",
        max_length=max_length,
    )

    return tokens


class DGADataset(Dataset):
    def __init__(self, X: np.ndarray, y: np.ndarray, max_length: int = 50):
        self.classes = np.unique(y)
        self.X = X
        self.y = y

        # Initialize the BERT tokenizer
        self.tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
        self.max_length = max_length

    def __len__(self):
        return len(self.X)

    def __getitem__(self, index):
        domain = self.X[index]
        label = torch.tensor(
            np.where(self.classes == self.y[index]), dtype=torch.long
        ).squeeze()

        tokens = tokenize_data(
            domain,
            max_length=self.max_length,
            tokenizer=self.tokenizer,
        )
        input_ids = tokens["input_ids"][0]
        attention_mask = tokens["attention_mask"][0]

        return {
            "domain": domain,
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "label": label,
        }
