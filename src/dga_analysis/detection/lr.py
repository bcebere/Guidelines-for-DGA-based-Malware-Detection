# stdlib
from typing import Any

# third party
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import MinMaxScaler

# dga_analysis relative
from .base import BaseDetector


class LinearClassifier(BaseDetector):
    """Classification plugin based on the Logistic Regression classifier.

    Method:
        Logistic regression is a linear model for classification rather than regression. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function.

    Args:
        C: float
            Inverse of regularization strength; must be a positive float.
        solver: str
            Algorithm to use in the optimization problem: [‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’]
        multi_class: str
            If the option chosen is ‘ovr’, then a binary problem is fit for each label. For ‘multinomial’ the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. ‘multinomial’ is unavailable when solver=’liblinear’. ‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’.
        class_weight: str
            Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.
        max_iter: int
            Maximum number of iterations taken for the solvers to converge.

    """

    solvers = ["newton-cg", "lbfgs", "sag", "saga"]
    classes = ["auto", "ovr", "multinomial"]
    weights = ["balanced", None]

    def __init__(
        self,
        C: float = 1.0,
        solver: int = 1,
        multi_class: int = 0,
        class_weight: int = 0,
        max_iter: int = 1000,
        penalty: str = "l2",
        random_state: int = 0,
        **kwargs: Any
    ) -> None:
        self.model = LogisticRegression(
            C=C,
            solver=LinearClassifier.solvers[solver],
            multi_class=LinearClassifier.classes[multi_class],
            class_weight=LinearClassifier.weights[class_weight],
            penalty=penalty,
            max_iter=max_iter,
            random_state=random_state,
            n_jobs=4,
            verbose=0,
        )

    def fit(self, X: np.ndarray, y: np.ndarray) -> "LinearClassifier":
        X = np.asarray(X)
        y = np.asarray(y)

        self.scaler = MinMaxScaler().fit(X)
        X = self.scaler.transform(X)

        self.model.fit(X, y)
        return self

    def predict(self, X: pd.DataFrame, *args: Any, **kwargs: Any) -> pd.DataFrame:
        X = np.asarray(X)

        X = self.scaler.transform(X)

        return self.model.predict(X, *args, **kwargs)

    def predict_proba(self, X: pd.DataFrame, *args: Any, **kwargs: Any) -> pd.DataFrame:
        X = np.asarray(X)
        X = self.scaler.transform(X)

        return self.model.predict_proba(X, *args, **kwargs)

    @staticmethod
    def name() -> str:
        return "logistic_regression"
