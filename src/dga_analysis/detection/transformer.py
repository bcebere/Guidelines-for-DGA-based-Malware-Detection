# stdlib
from typing import Any, Tuple

# third party
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader
from tqdm import tqdm
from tsai.models.TransformerModel import TransformerModel

# dga_analysis absolute
import dga_analysis.logger as log
from dga_analysis.utils.constants import DEVICE
from dga_analysis.utils.dga_nn_dataset import DGADataset, tokenize_data

# dga_analysis relative
from .base import BaseDetector


class TransformerImpl(nn.Module):
    def __init__(
        self,
        tokenizer: Any,
        n_units_emb: int = 128,
        output_dim: int = 2,
        n_layers: int = 2,
        dropout: float = 0.1,
    ):
        super().__init__()
        self.embedding = nn.Embedding(len(tokenizer.get_vocab()), n_units_emb)

        self.transformer = TransformerModel(
            c_in=n_units_emb,
            c_out=output_dim,
            n_layers=n_layers,
            dropout=dropout,
        )
        self.act = nn.Softmax(dim=-1)
        self.dropout = nn.Dropout(dropout)

    def forward(self, ids):
        # ids = [batch size, seq len]
        embedded = self.dropout(self.embedding(ids))
        embedded = embedded.permute(0, 2, 1)
        conv = self.transformer(embedded)
        return self.act(conv)


class TransformerClassifier(BaseDetector):
    def __init__(
        self,
        lr: float = 1e-3,
        n_units_emb: int = 128,
        n_layers: int = 2,
        dropout: float = 0.1,
        n_iter: int = 100,
        batch_size: int = 100,
        device=DEVICE,
        patience: int = 10,
        emb_max_len: int = 50,
    ) -> None:
        self.lr = lr
        self.n_units_emb = n_units_emb
        self.n_layers = n_layers
        self.dropout = dropout
        self.n_iter = n_iter
        self.device = device
        self.criterion = nn.CrossEntropyLoss()
        self.batch_size = batch_size
        self.patience = patience
        self.emb_max_len = emb_max_len

    def fit(self, X: Any, y: Any) -> "TransformerClassifier":
        return self._fit(X, y)

    def predict(self, X: np.ndarray) -> np.ndarray:
        probas = self.predict_proba(X)

        return np.argmax(probas, -1).squeeze()

    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        self.model.eval()

        X = np.asarray(X).squeeze().tolist()
        batch = tokenize_data(X, max_length=self.emb_max_len, tokenizer=self.tokenizer)
        input_ids = batch["input_ids"]
        attention_mask = batch["attention_mask"]

        input_ids = input_ids.to(self.device)
        attention_mask = attention_mask.to(self.device)

        # Forward pass
        outputs = self.model(input_ids)

        return outputs.cpu().detach().numpy().squeeze()

    @staticmethod
    def name() -> str:
        return "transformer"

    def _fit(self, X: np.ndarray, y: np.ndarray) -> "TransformerClassifier":
        output_dim = len(np.unique(y))

        X = np.asarray(X).squeeze()
        y = np.asarray(y).squeeze()

        X_train, X_test, y_train, y_test = train_test_split(X, y)

        # Creating instances of training and validation dataset
        train_set = DGADataset(X_train, y_train, max_length=self.emb_max_len)
        val_set = DGADataset(X_test, y_test, max_length=self.emb_max_len)
        self.tokenizer = train_set.tokenizer

        # Creating instances of training and validation dataloaders
        train_loader = DataLoader(train_set, batch_size=self.batch_size, shuffle=True)
        val_loader = DataLoader(val_set, batch_size=self.batch_size)

        # Instantiate the model
        self.model = TransformerImpl(
            self.tokenizer,
            n_layers=self.n_layers,
            n_units_emb=self.n_units_emb,
            output_dim=output_dim,
            dropout=self.dropout,
        )
        self.model = self.model.to(self.device)
        self.criterion = self.criterion.to(self.device)

        # Define loss function and optimizer
        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)

        # Training loop
        best_val_loss = 9999
        patience = 0
        for epoch in tqdm(range(self.n_iter)):
            train_loss = self._train_one_epoch(train_loader, optimizer)
            val_loss, _ = self._evaluate_one_epoch(val_loader)
            if best_val_loss <= val_loss:
                patience += 1
            else:
                patience = 0
                best_val_loss = val_loss
            if patience > self.patience:
                log.info("Run out of patience")
                break

            if epoch % 100 == 1:
                log.info(
                    f"Epoch: {epoch+1} | Train loss: {train_loss:.3f} | Val loss: {val_loss:.3f} | patience = {patience}"
                )

    def _train_one_epoch(self, data_loader: DataLoader, optimizer: Any) -> torch.Tensor:
        self.model.train()
        epoch_loss = 0
        epoch_accuracy = 0

        for i, batch in enumerate(data_loader):
            input_ids = batch["input_ids"]
            attention_mask = batch["attention_mask"]
            labels = batch["label"]

            # Move tensors to GPU
            input_ids = input_ids.to(self.device)
            attention_mask = attention_mask.to(self.device)
            labels = labels.to(self.device)

            # Forward pass
            outputs = self.model(input_ids)
            accuracy = (outputs.argmax(dim=1) == labels).float().mean()
            # Compute loss
            loss = self.criterion(outputs, labels)

            # Backward pass and optimization
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()
            epoch_accuracy += accuracy.item()
        return epoch_loss / len(data_loader)

    def _evaluate_one_epoch(
        self, data_loader: DataLoader
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        self.model.eval()
        epoch_loss = 0
        epoch_accuracy = 0

        with torch.no_grad():
            for i, batch in enumerate(data_loader):
                input_ids = batch["input_ids"]
                attention_mask = batch["attention_mask"]
                labels = batch["label"]

                # Move tensors to GPU
                input_ids = input_ids.to(self.device)
                attention_mask = attention_mask.to(self.device)
                labels = labels.to(self.device)

                # Forward pass
                outputs = self.model(input_ids)
                accuracy = (outputs.argmax(dim=1) == labels).float().mean()

                # Compute loss
                loss = self.criterion(outputs, labels)

                epoch_loss += loss.item()
                epoch_accuracy += accuracy.item()

        return epoch_loss / len(data_loader), epoch_accuracy / len(data_loader)
