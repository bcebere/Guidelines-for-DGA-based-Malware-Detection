{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957bba3-b479-4243-a3f4-d90169ac8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from tldextract import extract\n",
    "\n",
    "# dga_analysis absolute\n",
    "from dga_analysis.datasets.dataset_altered_benign import STRATEGIES, DatasetAltered\n",
    "from dga_analysis.datasets.dataset_dgarchive import FAMILIES as DGA_FAMILIES\n",
    "from dga_analysis.datasets.dataset_mixed import DatasetMixed\n",
    "from dga_analysis.datasets.dataset_synthetic_dga import FAMILIES as SYN_FAMILIES\n",
    "from dga_analysis.datasets.dataset_tranco import TYPOS, DatasetTranco\n",
    "from dga_analysis.detection.cnn import CNNClassifier\n",
    "from dga_analysis.detection.ji import JIClassifier\n",
    "from dga_analysis.detection.knn import KNNClassifier\n",
    "from dga_analysis.detection.lr import LinearClassifier\n",
    "from dga_analysis.detection.nn import NeuralNetClassifier\n",
    "from dga_analysis.detection.recurrent import (\n",
    "    GRUClassifier,\n",
    "    LSTMClassifier,\n",
    "    RecurrentClassifier,\n",
    "    RNNClassifier,\n",
    ")\n",
    "from dga_analysis.detection.rescnn import ResCNNClassifier\n",
    "from dga_analysis.detection.rf import RFClassifier\n",
    "from dga_analysis.detection.svm import SVMClassifier\n",
    "from dga_analysis.detection.transformer import TransformerClassifier\n",
    "from dga_analysis.detection.tree import DecisionTreeClassifier\n",
    "from dga_analysis.detection.xgb import XGBoostClassifier\n",
    "from dga_analysis.utils.evaluation import evaluate_classifier\n",
    "from dga_analysis.utils.features.examples import ALL\n",
    "from dga_analysis.utils.serialization import (\n",
    "    dataframe_hash,\n",
    "    load_from_file,\n",
    "    save_to_file,\n",
    ")\n",
    "\n",
    "SAMPLE_SIZE = 40000\n",
    "DGA_SUBSAMPLES = 20000\n",
    "WORKSPACE = Path(\"workspace_typo\")\n",
    "WORKSPACE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MULTICLASS = False\n",
    "MODELS_2D = [\n",
    "    \"rf\",\n",
    "    \"lr\",\n",
    "    # \"svm\",\n",
    "    \"xgb\",\n",
    "    \"tree\",\n",
    "    \"nn\",\n",
    "]\n",
    "\n",
    "MODELS_3D = [\n",
    "    # \"rnn\",\n",
    "    \"lstm\",\n",
    "    # \"gru\",\n",
    "    # \"transformer\",\n",
    "    \"cnn\",\n",
    "    \"rescnn\",\n",
    "    # \"ji\",\n",
    "]\n",
    "\n",
    "TEST_SIZE = 20000\n",
    "BENIGN_SUBSAMPLES = [20000]\n",
    "\n",
    "TEST_DATA = {}\n",
    "\n",
    "VERSION = \"v3\"\n",
    "full_testdata_bkp = WORKSPACE / f\"tranco_simple_typo_all_{TEST_SIZE}.v4.bkp\"\n",
    "\n",
    "if full_testdata_bkp.exists():\n",
    "    TEST_DATA = load_from_file(full_testdata_bkp)\n",
    "else:\n",
    "    for typo in TYPOS + [None]:\n",
    "        if typo is None:\n",
    "            typo_data = DatasetTranco(sample_size=TEST_SIZE, shuffle=False, typos=[])\n",
    "        else:\n",
    "            testdata_bkp = (\n",
    "                WORKSPACE / f\"tranco_simple_typo_{typo}_{TEST_SIZE}.{VERSION}.bkp\"\n",
    "            )\n",
    "            if testdata_bkp.exists():\n",
    "                typo_data = load_from_file(testdata_bkp)\n",
    "            else:\n",
    "                typo_data = DatasetTranco(\n",
    "                    sample_size=TEST_SIZE, shuffle=False, typos=[typo]\n",
    "                )\n",
    "                save_to_file(testdata_bkp, typo_data)\n",
    "        test_raw, _ = typo_data.raw_np(only_2ld=True)\n",
    "        test_embs, _ = typo_data.as_embeddings(only_2ld=True)\n",
    "        print(typo, test_raw[:10])\n",
    "        # test_stats, _ = typo_data.as_statistical(only_2ld=True)\n",
    "        TEST_DATA[typo] = {\n",
    "            \"raw\": test_raw,\n",
    "            \"embs\": test_embs,\n",
    "            # \"stats\" : test_stats,\n",
    "        }\n",
    "    save_to_file(full_testdata_bkp, TEST_DATA)\n",
    "\n",
    "\n",
    "def load_model(model: str):\n",
    "    if model == \"rf\":\n",
    "        return RFClassifier()\n",
    "    elif model == \"lr\":\n",
    "        return LinearClassifier()\n",
    "    elif model == \"svm\":\n",
    "        return SVMClassifier()\n",
    "    elif model == \"xgb\":\n",
    "        return XGBoostClassifier()\n",
    "    elif model == \"tree\":\n",
    "        return DecisionTreeClassifier()\n",
    "    elif model == \"nn\":\n",
    "        return NeuralNetClassifier(\n",
    "            n_layers_hidden=2,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"cnn\":\n",
    "        return CNNClassifier(\n",
    "            n_units_emb=256,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"ji\":\n",
    "        return JIClassifier()\n",
    "    elif model == \"transformer\":\n",
    "        return TransformerClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"lstm\":\n",
    "        return LSTMClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"rnn\":\n",
    "        return RNNClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"gru\":\n",
    "        return GRUClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"rescnn\":\n",
    "        return ResCNNClassifier(\n",
    "            n_units_emb=256,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplemented(model)\n",
    "\n",
    "\n",
    "def load_dgarchive_family(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"dgarchive\": 0.5},\n",
    "        multiclass=MULTICLASS,\n",
    "        dga_families=[family],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def benchmark_family_2d(typo: str, family: str, scenario: str, X, y):\n",
    "    if scenario == \"raw\":\n",
    "        models = MODELS_3D\n",
    "        Xtest = TEST_DATA[typo][\"raw\"]\n",
    "    elif scenario == \"embs\":\n",
    "        models = MODELS_2D\n",
    "        Xtest = TEST_DATA[typo][\"embs\"]\n",
    "    else:\n",
    "        models = MODELS_2D\n",
    "        Xtest = TEST_DATA[typo][\"stats\"]\n",
    "\n",
    "    X = np.asarray(X)\n",
    "\n",
    "    data_hash = dataframe_hash(pd.DataFrame(X))\n",
    "\n",
    "    best_score = None\n",
    "    min_fps = 9999999999999\n",
    "\n",
    "    for model_name in models:\n",
    "        cache_file = (\n",
    "            WORKSPACE\n",
    "            / f\"benchmarks_typo_{typo}_{model_name}_{data_hash}_{TEST_SIZE}.{VERSION}.bkp\"\n",
    "        )\n",
    "        if cache_file.exists():\n",
    "            scores = load_from_file(cache_file)\n",
    "            # print(\n",
    "            #     \"cached\",\n",
    "            #     family,\n",
    "            #     typo,\n",
    "            #     model_name,\n",
    "            #     np.sum(scores),\n",
    "            #     flush=True,\n",
    "            # )\n",
    "            if np.sum(scores) < min_fps:\n",
    "                best_score = scores\n",
    "                min_fps = np.sum(scores)\n",
    "    return best_score\n",
    "\n",
    "\n",
    "def benchmark_dgarchive_2d(\n",
    "    typo: str,\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    try:\n",
    "        X, y = load_dgarchive_family(\n",
    "            family,\n",
    "            scenario=scenario,\n",
    "            max_benign_source=max_benign_source,\n",
    "            max_dga_source=max_dga_source,\n",
    "        )\n",
    "    except BaseException as e:\n",
    "        print(\"data load failed \", e)\n",
    "        return None\n",
    "    return benchmark_family_2d(typo, family, scenario, X, y)\n",
    "\n",
    "\n",
    "def load_synthetic_family(\n",
    "    family: str,\n",
    "    scenario: str = \"stats\",\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 10000,\n",
    "):  # stats, embs, raw\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"synthetic_dga\": 0.5},\n",
    "        multiclass=MULTICLASS,\n",
    "        dga_families=[family],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True, max_length=100)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def benchmark_synthetic(\n",
    "    typo: str,\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 10000,\n",
    "):\n",
    "    try:\n",
    "        X, y = load_synthetic_family(\n",
    "            family,\n",
    "            scenario=scenario,\n",
    "            max_benign_source=max_benign_source,\n",
    "            max_dga_source=max_dga_source,\n",
    "        )\n",
    "    except BaseException as e:\n",
    "        print(\"data load failed \", e)\n",
    "        return None\n",
    "    return benchmark_family_2d(typo, family, scenario, X, y)\n",
    "\n",
    "\n",
    "def load_altered_family(\n",
    "    strategy: str, scenario: str, max_benign_source: int, max_dga_source: int\n",
    "):\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"altered_benign\": 0.5},\n",
    "        dga_families=[strategy],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def benchmark_altered_2d(\n",
    "    typo: str,\n",
    "    strategy: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    try:\n",
    "        X, y = load_altered_family(\n",
    "            strategy,\n",
    "            scenario=scenario,\n",
    "            max_benign_source=max_benign_source,\n",
    "            max_dga_source=max_dga_source,\n",
    "        )\n",
    "    except BaseException as e:\n",
    "        print(\"data load failed \", e)\n",
    "        return None\n",
    "    return benchmark_family_2d(typo, strategy, scenario, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994db59a-c1ae-464a-a047-30674c39bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cache_file = Path(f\"results/benchmark_benign_typos.v4.bkp\")\n",
    "\n",
    "if results_cache_file.exists():\n",
    "    results = load_from_file(results_cache_file)\n",
    "else:\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e0bba-1c5a-4e7a-94f0-fef05f1df1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = [\"embs\", \"raw\"]\n",
    "\n",
    "\n",
    "def _collect_results(families, cbk, results):\n",
    "    for benign_size in BENIGN_SUBSAMPLES:\n",
    "        if benign_size not in results:\n",
    "            results[benign_size] = {}\n",
    "        for typo in TYPOS:\n",
    "            if typo not in results[benign_size]:\n",
    "                results[benign_size][typo] = {}\n",
    "            for family in families:\n",
    "                if family in results[benign_size][typo]:\n",
    "                    print(\"cached\", family, typo)\n",
    "                    continue\n",
    "\n",
    "                best_score = None\n",
    "                min_fps = 999999999999999\n",
    "\n",
    "                for scenario in SCENARIOS:\n",
    "                    local_scores = cbk(\n",
    "                        typo,\n",
    "                        family,\n",
    "                        scenario=scenario,\n",
    "                        max_benign_source=benign_size,\n",
    "                        max_dga_source=DGA_SUBSAMPLES,\n",
    "                    )\n",
    "                    if local_scores is None:\n",
    "                        continue\n",
    "                    if np.sum(local_scores) < min_fps:\n",
    "                        best_score = local_scores\n",
    "                        min_fps = np.sum(local_scores)\n",
    "                if best_score is None:\n",
    "                    print(\"missing \", benign_size, family, typo)\n",
    "                    continue\n",
    "                results[benign_size][typo][family] = best_score\n",
    "                print(benign_size, family, typo, min_fps)\n",
    "    return results\n",
    "\n",
    "\n",
    "results = _collect_results(DGA_FAMILIES, benchmark_dgarchive_2d, results)\n",
    "results = _collect_results(SYN_FAMILIES, benchmark_synthetic, results)\n",
    "results = _collect_results(STRATEGIES, benchmark_altered_2d, results)\n",
    "\n",
    "save_to_file(results_cache_file, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216d7d0-53a4-4a85-8f2e-12cc77e1a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_results = []\n",
    "\n",
    "pretty_labels = {\n",
    "    \"addition\": \"Addition\",\n",
    "    \"doubleReplacement\": \"Replacement\",\n",
    "    \"homoglyph\": \"Homoglyph\",\n",
    "    \"omission\": \"Omission\",\n",
    "    \"repetition\": \"Repetition\",\n",
    "    \"replacement\": \"Replacement\",\n",
    "    #'vowelSwap',\n",
    "    \"bitsquat\": \"Bitsquatting\",\n",
    "    \"change_order\": \"Char Swap\",\n",
    "}\n",
    "for benign_size in results:\n",
    "    for typo in [\n",
    "        \"addition\",\n",
    "        \"doubleReplacement\",\n",
    "        \"omission\",\n",
    "        \"repetition\",\n",
    "        \"change_order\",\n",
    "        \"bitsquat\",\n",
    "    ]:  # results[benign_size]:\n",
    "        if typo not in pretty_labels:\n",
    "            continue\n",
    "        if typo not in results[benign_size]:\n",
    "            continue\n",
    "        for family in results[benign_size][typo]:\n",
    "\n",
    "            fps = np.sum(results[benign_size][typo][family])\n",
    "            ratio = fps / len(results[benign_size][typo][family])\n",
    "            pretty_results.append([family, pretty_labels[typo], fps, ratio])\n",
    "\n",
    "\n",
    "pretty_results = pd.DataFrame(\n",
    "    pretty_results, columns=[\"Family\", \"Typo\", \"FP Count\", \"FP Ratio\"]\n",
    ")\n",
    "\n",
    "pretty_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7a1bc-b3d5-4e4a-a9c8-08cb7f96002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGRAMS = Path(\"diagrams\")\n",
    "DIAGRAMS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# third party\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# libraries & dataset\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "FONT_SIZE = 18\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "custom_colors = prop_cycle.by_key()[\"color\"]\n",
    "custom_colors.extend(\n",
    "    [\n",
    "        \"#c5b0d5\",\n",
    "        \"#ffc500\",\n",
    "        \"#700548\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def format_func(value, tick_number):\n",
    "    return f\"{value:.1f}\"\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7, 3))\n",
    "ax = plt.gca()\n",
    "\n",
    "# hue_palette = [custom_colors[0], custom_colors[1], custom_colors[3], custom_colors[11], ]\n",
    "hatches = [\n",
    "    \"////\",\n",
    "    \"\\\\\\\\\\\\\\\\\\\\\",\n",
    "    \"|||||\",\n",
    "    \"xxxx\",\n",
    "    \"ooo\",\n",
    "    \"----\",\n",
    "    \"XXXXX\",\n",
    "    \"OO\",\n",
    "    \"////////\",\n",
    "]\n",
    "\n",
    "bp = sns.boxplot(\n",
    "    x=pretty_results[\"Typo\"],\n",
    "    y=pretty_results[\"FP Ratio\"],\n",
    "    # hue = pretty_results[\"Train Size\"],\n",
    "    # palette=hue_palette,\n",
    "    color=\"white\",  # custom_colors[1],\n",
    "    linecolor=custom_colors[1],\n",
    "    fliersize=7,\n",
    "    # flierprops={ \"marker\": \"o\",  \"markeredgecolor\": custom_colors[3], \"color\": \"white\", \"markerfacecolor\": custom_colors[3], \"alpha\": 0.2},\n",
    "    boxprops={\"facecolor\": \"none\", \"linewidth\": 2, \"alpha\": 0.9, \"hatch\": \"//////\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"solid\"},\n",
    "    meanline=True,\n",
    "    showmeans=True,\n",
    "    meanprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"dashdot\"},\n",
    ")\n",
    "for i, bar in enumerate(bp.patches):\n",
    "    if not isinstance(bar, matplotlib.patches.PathPatch):\n",
    "        continue\n",
    "    bar.set_hatch(hatches[int(i)])\n",
    "    # bar.set_edgecolor(hue_palette[int(i)])\n",
    "\n",
    "\n",
    "# ax0.set_xlabel(\"Performance Metric\", fontsize = FONT_SIZE)\n",
    "fig.text(0.55, -0.05, \"Simulated Typo Scenario\", fontsize=FONT_SIZE, ha=\"center\")\n",
    "ax.set_ylabel(\"FP Ratio\", fontsize=FONT_SIZE)\n",
    "ax.set_xlabel(None)\n",
    "\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "\n",
    "plt.xticks(rotation=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "figname = \"benchmarks_benign_typos\"\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928f6f4-d08f-4493-b26a-917f2dbdd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_results[\"Typo\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8d071-8312-419c-a415-4ac543e667d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_results.sort_values(\"FP Ratio\").tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca14234-f97e-416a-8b33-d00ae5be7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "typos = pretty_results[\"Typo\"].unique()\n",
    "\n",
    "for typo in typos:\n",
    "    print(typo, pretty_results[pretty_results[\"Typo\"] == typo][\"FP Ratio\"].mean())\n",
    "    print(\n",
    "        typo,\n",
    "        pretty_results[pretty_results[\"Typo\"] == typo].sort_values(\"FP Ratio\").tail(10),\n",
    "    )\n",
    "\n",
    "typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bb901-e952-47b5-8c61-d045fe56475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA[\"bitsquat\"][\"raw\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b563a0-37b5-48bc-8fa6-ba7d3e5c0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "test_string = \"merequaṙtz\"\n",
    "\n",
    "# encode Converts a string in a sequence of ids (integer), using the tokenizer and vocabulary.\n",
    "input_ids = tokenizer.encode(test_string)\n",
    "output = tokenizer.decode(input_ids)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e12878-f6cd-4a12-901c-a7f75a60944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for benign_size in results:\n",
    "    for typo in [\"addition\"]:  # results[benign_size]:\n",
    "        if typo not in results[benign_size]:\n",
    "            continue\n",
    "        for family in [\"pykspa_dga\"]:\n",
    "            print(np.sum(results[benign_size][typo][family]))\n",
    "            print(\n",
    "                pd.Series(TEST_DATA[typo][\"raw\"])[\n",
    "                    results[benign_size][typo][family].astype(bool)\n",
    "                ].tolist()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3caa1a-e41c-4855-b70d-e465a699b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA[\"homoglyph\"][\"raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd072a3d-9d1c-45f8-bd8c-cc4198f2241f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dga",
   "language": "python",
   "name": "dga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
