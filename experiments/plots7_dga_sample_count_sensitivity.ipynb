{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95903f4-ca68-4b86-a3ab-5292ed43b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# stdlib\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from tldextract import extract\n",
    "\n",
    "# dga_analysis absolute\n",
    "from dga_analysis.datasets.dataset_altered_benign import STRATEGIES, DatasetAltered\n",
    "from dga_analysis.datasets.dataset_dgarchive import FAMILIES as DGA_FAMILIES\n",
    "from dga_analysis.datasets.dataset_mixed import DatasetMixed\n",
    "from dga_analysis.datasets.dataset_synthetic_dga import FAMILIES as SYN_FAMILIES\n",
    "from dga_analysis.detection.cnn import CNNClassifier\n",
    "from dga_analysis.detection.ji import JIClassifier\n",
    "from dga_analysis.detection.knn import KNNClassifier\n",
    "from dga_analysis.detection.lr import LinearClassifier\n",
    "from dga_analysis.detection.nn import NeuralNetClassifier\n",
    "from dga_analysis.detection.recurrent import (\n",
    "    GRUClassifier,\n",
    "    LSTMClassifier,\n",
    "    RecurrentClassifier,\n",
    "    RNNClassifier,\n",
    ")\n",
    "from dga_analysis.detection.rescnn import ResCNNClassifier\n",
    "from dga_analysis.detection.rf import RFClassifier\n",
    "from dga_analysis.detection.svm import SVMClassifier\n",
    "from dga_analysis.detection.transformer import TransformerClassifier\n",
    "from dga_analysis.detection.tree import DecisionTreeClassifier\n",
    "from dga_analysis.detection.xgb import XGBoostClassifier\n",
    "from dga_analysis.utils.evaluation import evaluate_classifier\n",
    "from dga_analysis.utils.features.examples import ALL\n",
    "from dga_analysis.utils.serialization import (\n",
    "    dataframe_hash,\n",
    "    load_from_file,\n",
    "    save_to_file,\n",
    ")\n",
    "\n",
    "SAMPLE_SIZE = 150000\n",
    "BENIGN_SUBSAMPLES = 20000\n",
    "\n",
    "WORKSPACE = Path(\"workspace\")\n",
    "WORKSPACE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DIAGRAMS = Path(\"diagrams\")\n",
    "DIAGRAMS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MULTICLASS = False\n",
    "\n",
    "MODELS_2D = [\n",
    "    \"rf\",\n",
    "    \"lr\",\n",
    "    # \"svm\",\n",
    "    \"xgb\",\n",
    "    \"tree\",\n",
    "    # \"nn\",\n",
    "]\n",
    "\n",
    "MODELS_3D = [\n",
    "    # \"rnn\",\n",
    "    \"lstm\",\n",
    "    # \"gru\",\n",
    "    \"transformer\",\n",
    "    \"cnn\",\n",
    "    \"rescnn\",\n",
    "    # \"ji\",\n",
    "]\n",
    "SCENARIOS = [\"raw\", \"embs\", \"stats\"]\n",
    "\n",
    "\n",
    "def load_model(model: str):\n",
    "    if model == \"rf\":\n",
    "        return RFClassifier()\n",
    "    elif model == \"lr\":\n",
    "        return LinearClassifier()\n",
    "    elif model == \"svm\":\n",
    "        return SVMClassifier()\n",
    "    elif model == \"xgb\":\n",
    "        return XGBoostClassifier()\n",
    "    elif model == \"tree\":\n",
    "        return DecisionTreeClassifier()\n",
    "    elif model == \"nn\":\n",
    "        return NeuralNetClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"cnn\":\n",
    "        return CNNClassifier(\n",
    "            n_units_emb=256,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"ji\":\n",
    "        return JIClassifier()\n",
    "    elif model == \"transformer\":\n",
    "        return TransformerClassifier(\n",
    "            n_layers=1,\n",
    "            n_units_emb=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"lstm\":\n",
    "        return LSTMClassifier(\n",
    "            n_layers=1,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"rnn\":\n",
    "        return RNNClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"gru\":\n",
    "        return GRUClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"rescnn\":\n",
    "        return ResCNNClassifier(\n",
    "            n_units_emb=256,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplemented(model)\n",
    "\n",
    "\n",
    "def load_dgarchive_family(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"dgarchive\": 0.5},\n",
    "        multiclass=MULTICLASS,\n",
    "        dga_families=[family],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    # print(\"load\", family, scenario, max_benign_source, max_dga_source)\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def load_altered_family(\n",
    "    altered: str, scenario: str, max_benign_source: int, max_dga_source: int\n",
    "):\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"altered_benign\": 0.5},\n",
    "        dga_families=[strategy],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def load_synthetic_family(\n",
    "    family: str,\n",
    "    scenario: str = \"stats\",\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 10000,\n",
    "):  # stats, embs, raw\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"synthetic_dga\": 0.5},\n",
    "        multiclass=MULTICLASS,\n",
    "        dga_families=[family],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True, max_length=100)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def get_results_family_2d(family: str, scenario: str, X, y):\n",
    "    if scenario == \"raw\":\n",
    "        models = MODELS_3D\n",
    "    else:\n",
    "        models = MODELS_2D\n",
    "    X = np.asarray(X)\n",
    "\n",
    "    data_hash = dataframe_hash(pd.DataFrame(X))\n",
    "\n",
    "    best_results = None\n",
    "    best_f1 = -1\n",
    "    for model_name in models:\n",
    "        cache_file = (\n",
    "            WORKSPACE\n",
    "            / f\"benchmarks_{model_name}_{data_hash}_{len(np.unique(y))}.v2.bkp\"\n",
    "        )\n",
    "        if cache_file.exists():\n",
    "            scores = load_from_file(cache_file)\n",
    "            current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_results = scores\n",
    "\n",
    "            # print(\"FOUND \", family, model_name, cache_file)\n",
    "\n",
    "            # print(\n",
    "            #     family,\n",
    "            #     model_name,\n",
    "            #     scenario,\n",
    "            #     pd.Series(y).value_counts().to_dict(),\n",
    "            #     scores[\"str\"],\n",
    "            #     flush=True,\n",
    "            # )\n",
    "            continue\n",
    "\n",
    "    return best_results\n",
    "\n",
    "\n",
    "def benchmark_dgarchive_2d(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    X, y = load_dgarchive_family(\n",
    "        family,\n",
    "        scenario=scenario,\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    return get_results_family_2d(family, scenario, X, y)\n",
    "\n",
    "\n",
    "def benchmark_synthetic(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 10000,\n",
    "):\n",
    "    X, y = load_synthetic_family(\n",
    "        family,\n",
    "        scenario=scenario,\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    return get_results_family_2d(family, scenario, X, y)\n",
    "\n",
    "\n",
    "def benchmark_altered_2d(\n",
    "    strategy: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    X, y = load_altered_family(\n",
    "        strategy,\n",
    "        scenario=scenario,\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    print(\"altered\", pd.Series(y).value_counts().to_dict())\n",
    "    return get_results_family_2d(strategy, scenario, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59923494-9ac2-4f28-a132-c19cc85c35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = [\"stats\", \"embs\", \"raw\"]\n",
    "DGA_SUBSAMPLES = [100, 1000, 10000, 20000]\n",
    "\n",
    "results_cache_file = Path(\"results/benchmark_dga_sample_count_sensitivity.bkp\")\n",
    "if results_cache_file.exists():\n",
    "    all_results = load_from_file(results_cache_file)\n",
    "else:\n",
    "    all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c03346-194b-434b-946d-4a293c6ea46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dga_subsamples in DGA_SUBSAMPLES:\n",
    "    if dga_subsamples not in all_results:\n",
    "        all_results[dga_subsamples] = {}\n",
    "\n",
    "    for family in DGA_FAMILIES:\n",
    "        if family in all_results[dga_subsamples]:\n",
    "            print(\n",
    "                \"cached\",\n",
    "                family,\n",
    "                dga_subsamples,\n",
    "                all_results[dga_subsamples][family][\"str\"][\"f1_score_macro\"],\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        best_results = None\n",
    "        best_f1 = -1\n",
    "\n",
    "        for scenario in SCENARIOS:\n",
    "            scores = benchmark_dgarchive_2d(\n",
    "                family,\n",
    "                scenario=scenario,\n",
    "                max_benign_source=BENIGN_SUBSAMPLES,\n",
    "                max_dga_source=dga_subsamples,\n",
    "            )\n",
    "            if scores is None:\n",
    "                continue\n",
    "            current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_results = scores\n",
    "        if best_results is None:\n",
    "            print(\"missing results\", family)\n",
    "            continue\n",
    "        print(family, dga_subsamples, best_results[\"str\"][\"f1_score_macro\"])\n",
    "        all_results[dga_subsamples][family] = best_results\n",
    "        save_to_file(results_cache_file, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66178fbe-b99c-4c9d-9b0e-3de6ef5c77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dga_subsamples in DGA_SUBSAMPLES:\n",
    "    if dga_subsamples not in all_results:\n",
    "        all_results[dga_subsamples] = {}\n",
    "\n",
    "    for family in SYN_FAMILIES:\n",
    "        if family in all_results[dga_subsamples]:\n",
    "            print(\"cached\", family, dga_subsamples)\n",
    "            continue\n",
    "\n",
    "        best_results = None\n",
    "        best_f1 = -1\n",
    "\n",
    "        for scenario in SCENARIOS:\n",
    "            scores = benchmark_synthetic(\n",
    "                family,\n",
    "                scenario=scenario,\n",
    "                max_benign_source=BENIGN_SUBSAMPLES,\n",
    "                max_dga_source=dga_subsamples,\n",
    "            )\n",
    "            if scores is None:\n",
    "                continue\n",
    "            current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_results = scores\n",
    "\n",
    "        if best_results is None:\n",
    "            print(\"missing results\", family)\n",
    "            continue\n",
    "        print(family, dga_subsamples, best_results[\"str\"][\"f1_score_macro\"])\n",
    "        all_results[dga_subsamples][family] = best_results\n",
    "        save_to_file(results_cache_file, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709c092-6f76-488b-88a2-d23d4c923930",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dga_subsamples in DGA_SUBSAMPLES:\n",
    "    if dga_subsamples not in all_results:\n",
    "        all_results[dga_subsamples] = {}\n",
    "\n",
    "    for strategy in STRATEGIES:\n",
    "        if strategy in all_results[dga_subsamples]:\n",
    "            print(\"cached\", strategy, dga_subsamples)\n",
    "            continue\n",
    "\n",
    "        best_results = None\n",
    "        best_f1 = -1\n",
    "\n",
    "        for scenario in SCENARIOS:\n",
    "            scores = benchmark_altered_2d(\n",
    "                strategy,\n",
    "                scenario=scenario,\n",
    "                max_benign_source=BENIGN_SUBSAMPLES,\n",
    "                max_dga_source=dga_subsamples,\n",
    "            )\n",
    "            if scores is None:\n",
    "                continue\n",
    "            current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_results = scores\n",
    "\n",
    "        if best_results is None:\n",
    "            print(\"missing results\", family)\n",
    "            continue\n",
    "        print(strategy, best_results[\"str\"][\"f1_score_macro\"])\n",
    "        all_results[dga_subsamples][strategy] = best_results\n",
    "        save_to_file(results_cache_file, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b0fdf-e8dc-44db-89e3-c5dd5560ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0913f-f102-456a-9195-db6e991025ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics = []\n",
    "raw_metrics = []\n",
    "raw_mcc_metrics = []\n",
    "\n",
    "interesting_fams = [\n",
    "    # arithemtic\n",
    "    \"bobax_dga\",\n",
    "    \"conficker_dga\",\n",
    "    \"goznym_dga\",\n",
    "    \"proslikefan_dga\",\n",
    "    \"pushdo_dga\",\n",
    "    \"pykspa_dga\",\n",
    "    \"qsnatch_dga\",\n",
    "    \"randomloader_dga\",\n",
    "    \"vawtrak_dga\",\n",
    "    \"virut_dga\",\n",
    "    # dictionary\n",
    "    \"suppobox_dga\",\n",
    "    \"matsnu_dga\",\n",
    "    \"nymaim2_dga\",\n",
    "    \"nymaim_dga\",\n",
    "    \"DictSuppoboxTranco\",\n",
    "    \"DictGoziTranco\",\n",
    "    \"DictGoziEnglish\",\n",
    "    \"DictGTrends\",\n",
    "    # adversarial\n",
    "    \"Khaos\",\n",
    "    \"deception2_dga\",\n",
    "    \"deception_dga\",\n",
    "    \"CharBot\",\n",
    "    # permutation\n",
    "    \"permutation\",\n",
    "    \"alter_char\",\n",
    "    \"reverse\",\n",
    "]\n",
    "\n",
    "for dga_subsamples in DGA_SUBSAMPLES:\n",
    "    minval = 0\n",
    "    for family in all_results[dga_subsamples]:\n",
    "        if family not in interesting_fams:\n",
    "            continue\n",
    "        f1_metric = max(\n",
    "            minval, all_results[dga_subsamples][family][\"raw\"][\"f1_score_macro\"][0]\n",
    "        )\n",
    "        recall = max(\n",
    "            minval, all_results[dga_subsamples][family][\"raw\"][\"recall_macro\"][0]\n",
    "        )\n",
    "        precision = max(\n",
    "            minval, all_results[dga_subsamples][family][\"raw\"][\"precision_macro\"][0]\n",
    "        )\n",
    "        mcc = max(minval, all_results[dga_subsamples][family][\"raw\"][\"mcc\"][0])\n",
    "\n",
    "        # print(family, corruption, f1_metric)\n",
    "        plot_metrics.append([dga_subsamples, family, f1_metric, recall, precision, mcc])\n",
    "        raw_metrics.extend(\n",
    "            [\n",
    "                [dga_subsamples, family, \"F1 Score\", f1_metric],\n",
    "                [dga_subsamples, family, \"Recall\", recall],\n",
    "                [dga_subsamples, family, \"Precision\", precision],\n",
    "                # [dga_subsamples, family, \"MCC\", mcc],\n",
    "            ]\n",
    "        )\n",
    "        raw_mcc_metrics.extend(\n",
    "            [\n",
    "                [dga_subsamples, family, \"MCC\", mcc],\n",
    "            ]\n",
    "        )\n",
    "plot_metrics = pd.DataFrame(\n",
    "    plot_metrics,\n",
    "    columns=[\"Samples Count\", \"Family\", \"F1 Score\", \"Recall\", \"Precision\", \"MCC\"],\n",
    ")\n",
    "raw_metrics = pd.DataFrame(\n",
    "    raw_metrics, columns=[\"Samples Count\", \"Family\", \"Metric\", \"Score\"]\n",
    ")\n",
    "raw_mcc_metrics = pd.DataFrame(\n",
    "    raw_mcc_metrics, columns=[\"Samples Count\", \"Family\", \"Metric\", \"Score\"]\n",
    ")\n",
    "\n",
    "raw_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d93d7a-5904-4454-86f0-a7d6b5f230e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libraries & dataset\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "FONT_SIZE = 18\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "custom_colors = prop_cycle.by_key()[\"color\"]\n",
    "custom_colors.extend(\n",
    "    [\n",
    "        \"#c5b0d5\",\n",
    "        \"#ffc500\",\n",
    "        \"#700548\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(17, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "hue_palette = [\n",
    "    custom_colors[0],\n",
    "    custom_colors[1],\n",
    "    custom_colors[3],\n",
    "    custom_colors[11],\n",
    "]\n",
    "hatches = [\"////\", \"\\\\\\\\\\\\\\\\\", \"||||\", \"xxx\"]\n",
    "bp = sns.boxplot(\n",
    "    x=raw_metrics[\"Samples Count\"],\n",
    "    y=raw_metrics[\"Score\"],\n",
    "    hue=raw_metrics[\"Metric\"],\n",
    "    palette=hue_palette,\n",
    "    # color = custom_colors[1],\n",
    "    # linecolor =  custom_colors[1],\n",
    "    fliersize=7,\n",
    "    # flierprops={ \"marker\": \"o\",  \"markeredgecolor\": custom_colors[3], \"color\": \"white\", \"markerfacecolor\": custom_colors[3], \"alpha\": 0.2},\n",
    "    boxprops={\"facecolor\": \"none\", \"linewidth\": 2, \"alpha\": 0.9, \"hatch\": \"//////\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"solid\"},\n",
    "    meanline=True,\n",
    "    showmeans=True,\n",
    "    meanprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"dashdot\"},\n",
    ")\n",
    "\n",
    "for i, bar in enumerate(bp.patches):\n",
    "    if not isinstance(bar, matplotlib.patches.PathPatch):\n",
    "        continue\n",
    "    bar.set_hatch(hatches[int(i / 4)])\n",
    "    bar.set_edgecolor(hue_palette[int(i / 4)])\n",
    "\n",
    "\n",
    "plt.xlabel(\"DGA Samples Count\", fontsize=FONT_SIZE)\n",
    "plt.ylabel(\"Score\", fontsize=FONT_SIZE)\n",
    "\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "legend = plt.legend(\n",
    "    loc=\"lower left\",\n",
    "    ncols=1,\n",
    "    fontsize=14,\n",
    ")\n",
    "handles = legend.legend_handles\n",
    "for i, handle in enumerate(handles):\n",
    "    handle.set_hatch(hatches[i])\n",
    "    handle.set_edgecolor(hue_palette[int(i % 4)])  # set_edgecolors\n",
    "    handle.set_facecolor(\"white\")\n",
    "\n",
    "figname = \"benchmarks_sample_count_sensitivity\"\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35bfcd5-3b09-49d4-9eea-8f817cb173b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libraries & dataset\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "FONT_SIZE = 18\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "custom_colors = prop_cycle.by_key()[\"color\"]\n",
    "custom_colors.extend(\n",
    "    [\n",
    "        \"#c5b0d5\",\n",
    "        \"#ffc500\",\n",
    "        \"#700548\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(\n",
    "    1, 2, figsize=(17, 4), gridspec_kw={\"width_ratios\": [3, 1]}\n",
    ")\n",
    "\n",
    "hue_palette = [\n",
    "    custom_colors[0],\n",
    "    custom_colors[1],\n",
    "    custom_colors[3],\n",
    "    custom_colors[11],\n",
    "]\n",
    "hatches = [\"////\", \"\\\\\\\\\\\\\\\\\", \"||||\", \"xxx\"]\n",
    "bp = sns.boxplot(\n",
    "    x=raw_metrics[\"Samples Count\"],\n",
    "    y=raw_metrics[\"Score\"],\n",
    "    hue=raw_metrics[\"Metric\"],\n",
    "    palette=hue_palette,\n",
    "    # color = custom_colors[1],\n",
    "    # linecolor =  custom_colors[1],\n",
    "    fliersize=7,\n",
    "    # flierprops={ \"marker\": \"o\",  \"markeredgecolor\": custom_colors[3], \"color\": \"white\", \"markerfacecolor\": custom_colors[3], \"alpha\": 0.2},\n",
    "    boxprops={\"facecolor\": \"none\", \"linewidth\": 2, \"alpha\": 0.9, \"hatch\": \"//////\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"solid\"},\n",
    "    meanline=True,\n",
    "    showmeans=True,\n",
    "    meanprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"dashdot\"},\n",
    "    ax=ax0,\n",
    ")\n",
    "\n",
    "for i, bar in enumerate(bp.patches):\n",
    "    if not isinstance(bar, matplotlib.patches.PathPatch):\n",
    "        continue\n",
    "    bar.set_hatch(hatches[int(i / 4)])\n",
    "    bar.set_edgecolor(hue_palette[int(i / 4)])\n",
    "\n",
    "bp = sns.boxplot(\n",
    "    x=raw_mcc_metrics[\"Samples Count\"],\n",
    "    y=raw_mcc_metrics[\"Score\"],\n",
    "    hue=raw_mcc_metrics[\"Metric\"],\n",
    "    palette=hue_palette,\n",
    "    # color = custom_colors[1],\n",
    "    # linecolor =  custom_colors[1],\n",
    "    fliersize=7,\n",
    "    # flierprops={ \"marker\": \"o\",  \"markeredgecolor\": custom_colors[3], \"color\": \"white\", \"markerfacecolor\": custom_colors[3], \"alpha\": 0.2},\n",
    "    boxprops={\"facecolor\": \"none\", \"linewidth\": 2, \"alpha\": 0.9, \"hatch\": \"//////\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"solid\"},\n",
    "    meanline=True,\n",
    "    showmeans=True,\n",
    "    meanprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"dashdot\"},\n",
    "    ax=ax1,\n",
    ")\n",
    "\n",
    "for i, bar in enumerate(bp.patches):\n",
    "    if not isinstance(bar, matplotlib.patches.PathPatch):\n",
    "        continue\n",
    "    bar.set_hatch(\"xxx\")\n",
    "    bar.set_edgecolor(custom_colors[11])\n",
    "\n",
    "# plt.xlabel(\"DGA Samples Count\", fontsize = FONT_SIZE)\n",
    "# plt.ylabel(\"Score\", fontsize = FONT_SIZE)\n",
    "\n",
    "ax0.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax0.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "ax1.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax1.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "legend = ax0.legend(\n",
    "    loc=\"upper left\",\n",
    "    ncols=1,\n",
    "    fontsize=14,\n",
    ")\n",
    "handles = legend.legend_handles\n",
    "for i, handle in enumerate(handles):\n",
    "    handle.set_hatch(hatches[i])\n",
    "    handle.set_edgecolor(hue_palette[int(i % 4)])  # set_edgecolors\n",
    "    handle.set_facecolor(\"white\")\n",
    "\n",
    "legend = ax1.legend(\n",
    "    loc=\"upper left\",\n",
    "    ncols=1,\n",
    "    fontsize=14,\n",
    ")\n",
    "handles = legend.legend_handles\n",
    "for i, handle in enumerate(handles):\n",
    "    handle.set_hatch(\"xxx\")\n",
    "    handle.set_edgecolor(custom_colors[11])  # set_edgecolors\n",
    "    handle.set_facecolor(\"white\")\n",
    "\n",
    "fig.text(0.55, 0, \"DGA Samples Count\", fontsize=FONT_SIZE, ha=\"center\")\n",
    "ax0.set_ylabel(\"Score\", fontsize=FONT_SIZE)\n",
    "ax1.set_ylabel(None)\n",
    "ax1.set_xlabel(None)\n",
    "ax0.set_xlabel(None)\n",
    "\n",
    "ax0.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax0.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "ax1.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax1.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "\n",
    "plt.subplots_adjust(hspace=0, wspace=0.07)\n",
    "\n",
    "figname = \"benchmarks_sample_count_sensitivity\"\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463fc6ea-219d-4c75-88c8-a46a154a9819",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics[(plot_metrics[\"Samples Count\"] == 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afb672-e18c-4cb0-aff6-22b2f7110a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interesting_fams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85228375-416b-4588-ad71-4441fb7f8f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[100].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf66eb-9a02-4021-a4a4-cc8b0a1e0336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949ba8b-bf29-4797-a891-8037e5d77f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69b335-650a-455f-8bd3-05ce5955304b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dga",
   "language": "python",
   "name": "dga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
