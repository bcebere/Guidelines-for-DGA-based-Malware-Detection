# stdlib
from pathlib import Path
from random import shuffle

# third party
import numpy as np
import pandas as pd
from joblib import Parallel, delayed
from sklearn.preprocessing import MinMaxScaler

# dga_analysis absolute
from dga_analysis.datasets.dataset_dgarchive import FAMILIES
from dga_analysis.datasets.dataset_mixed import DatasetMixed
from dga_analysis.datasets.dataset_synthetic_dga import FAMILIES as SYN_FAMILIES
from dga_analysis.detection.lr import LinearClassifier
from dga_analysis.detection.nn import NeuralNetClassifier
from dga_analysis.detection.rf import RFClassifier
from dga_analysis.detection.svm import SVMClassifier
from dga_analysis.detection.tree import DecisionTreeClassifier
from dga_analysis.detection.xgb import XGBoostClassifier
from dga_analysis.utils.evaluation import evaluate_classifier
from dga_analysis.utils.serialization import (
    dataframe_hash,
    load_from_file,
    save_to_file,
)

SAMPLE_SIZE = 150000
WORKSPACE = Path("workspace")
WORKSPACE.mkdir(parents=True, exist_ok=True)

MODELS_2D = [
    "rf",
    "lr",
    # "svm",
    "xgb",
    "tree",
    "nn",
]


def load_model(model: str):
    if model == "rf":
        return RFClassifier()
    elif model == "lr":
        return LinearClassifier()
    elif model == "svm":
        return SVMClassifier()
    elif model == "xgb":
        return XGBoostClassifier()
    elif model == "tree":
        return DecisionTreeClassifier()
    elif model == "nn":
        return NeuralNetClassifier()


def load_dgarchive_family(family: str, as_statistical: bool):
    dataset = DatasetMixed(
        sample_size=SAMPLE_SIZE,
        sources={"tranco": 0.5, "dgarchive": 0.5},
        multiclass=False,
        dga_families=[family],
    )

    if as_statistical:
        return dataset.as_statistical(only_2ld=True)
    else:
        return dataset.raw(only_2ld=True)


def benchmark_family_2d(family: str, X, y):
    X = MinMaxScaler().fit_transform(np.asarray(X))
    data_hash = dataframe_hash(pd.DataFrame(X))

    for model_name in MODELS_2D:
        cache_file = (
            WORKSPACE / f"benchmarks_{model_name}_{data_hash}_{len(np.unique(y))}.bkp"
        )
        if cache_file.exists():
            scores = load_from_file(cache_file)
            print("cached", family, model_name, scores["str"], flush=True)
            continue

        try:
            model = load_model(model_name)
            scores = evaluate_classifier(model, X, y)
            save_to_file(cache_file, scores)
            print("computed", family, model_name, scores["str"], flush=True)
        except BaseException as e:
            print("failed", family, model_name, e, flush=True)
            continue


shuffle(FAMILIES)
shuffle(FAMILIES)


def benchmark_families_2d(family: str):
    X, y = load_dgarchive_family(family, as_statistical=True)
    print(family, pd.Series(y).value_counts(), flush=True)
    benchmark_family_2d(family, X, y)


parallel = Parallel(n_jobs=10)
results = parallel(delayed(benchmark_families_2d)(family) for family in FAMILIES)


def load_synthetic_family(family: str, as_statistical: bool):
    dataset = DatasetMixed(
        sample_size=SAMPLE_SIZE,
        sources={"tranco": 0.5, "synthetic_dga": 0.5},
        multiclass=False,
        dga_families=[family],
    )

    if as_statistical:
        return dataset.as_statistical(only_2ld=True)
    else:
        return dataset.raw(only_2ld=True)


parallel = Parallel(n_jobs=10)
results = parallel(delayed(load_synthetic_family)(family) for family in SYN_FAMILIES)
