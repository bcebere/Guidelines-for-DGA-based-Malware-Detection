{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b3e84-f4f3-47e6-bfe4-ffa32c4654f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# stdlib\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from tldextract import extract\n",
    "\n",
    "# dga_analysis absolute\n",
    "from dga_analysis.datasets.dataset_altered_benign import STRATEGIES, DatasetAltered\n",
    "from dga_analysis.datasets.dataset_dgarchive import FAMILIES as DGA_FAMILIES\n",
    "from dga_analysis.datasets.dataset_dgarchive import DatasetDGArchive\n",
    "from dga_analysis.datasets.dataset_mixed import DatasetMixed\n",
    "from dga_analysis.datasets.dataset_synthetic_dga import FAMILIES as SYN_FAMILIES\n",
    "from dga_analysis.datasets.dataset_synthetic_dga import DatasetSyntheticDGA\n",
    "from dga_analysis.datasets.dataset_tranco import DatasetTranco\n",
    "from dga_analysis.detection.lr import LinearClassifier\n",
    "from dga_analysis.detection.nn import NeuralNetClassifier\n",
    "from dga_analysis.detection.rf import RFClassifier\n",
    "from dga_analysis.detection.svm import SVMClassifier\n",
    "from dga_analysis.detection.tree import DecisionTreeClassifier\n",
    "from dga_analysis.detection.xgb import XGBoostClassifier\n",
    "from dga_analysis.utils.evaluation import evaluate_classifier\n",
    "from dga_analysis.utils.features.examples import ALL\n",
    "from dga_analysis.utils.serialization import (\n",
    "    dataframe_hash,\n",
    "    load_from_file,\n",
    "    save_to_file,\n",
    ")\n",
    "\n",
    "WORKSPACE = Path(\"workspace\")\n",
    "WORKSPACE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MULTICLASS = True\n",
    "\n",
    "MODELS_2D = [\n",
    "    \"rf\",\n",
    "    \"lr\",\n",
    "    # \"svm\",\n",
    "    \"xgb\",\n",
    "    \"tree\",\n",
    "    # \"nn\",\n",
    "]\n",
    "\n",
    "\n",
    "def load_model(model: str):\n",
    "    if model == \"rf\":\n",
    "        return RFClassifier()\n",
    "    elif model == \"lr\":\n",
    "        return LinearClassifier()\n",
    "    elif model == \"svm\":\n",
    "        return SVMClassifier()\n",
    "    elif model == \"xgb\":\n",
    "        return XGBoostClassifier()\n",
    "    elif model == \"tree\":\n",
    "        return DecisionTreeClassifier()\n",
    "    elif model == \"nn\":\n",
    "        return NeuralNetClassifier()\n",
    "\n",
    "\n",
    "def load_tranco(scenario: str, benign_size: int, dataset_timestamp):\n",
    "    dataset = DatasetTranco(\n",
    "        sample_size=benign_size,\n",
    "        dataset_timestamp=dataset_timestamp,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def load_dgarchive(\n",
    "    scenario: str, dga_source_size: int, years: list\n",
    "):  # stats, embs, raw\n",
    "    dataset = DatasetDGArchive(\n",
    "        sample_size=len(DGA_FAMILIES) * dga_source_size,\n",
    "        max_source_size=dga_source_size,\n",
    "        filter_by_years=years,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True, max_length=100)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def load_synthetic_dga(scenario: str, dga_source_size: int):\n",
    "    dataset = DatasetSyntheticDGA(\n",
    "        sample_size=len(SYN_FAMILIES) * dga_source_size,\n",
    "        max_source_size=dga_source_size,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def load_altered(scenario: str, dga_source_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    for strategy in STRATEGIES:\n",
    "        dataset = DatasetAltered(\n",
    "            sample_size=dga_source_size,\n",
    "            strategy=strategy,\n",
    "        )\n",
    "\n",
    "        if scenario == \"stats\":\n",
    "            Xlocal, ylocal = dataset.as_statistical(only_2ld=True)\n",
    "        elif scenario == \"embs\":\n",
    "            Xlocal, ylocal = dataset.as_embeddings(only_2ld=True)\n",
    "        else:\n",
    "            Xlocal, ylocal = dataset.raw(only_2ld=True)\n",
    "\n",
    "        X.append(pd.DataFrame(Xlocal))\n",
    "        y.append(pd.Series(ylocal))\n",
    "    return pd.concat(X, ignore_index=True), pd.concat(y, ignore_index=True)\n",
    "\n",
    "\n",
    "def load_dataset(scenario: str, benign_size: int, dga_size: int, testcase):\n",
    "    train_benign_timestamp, train_dga_years, test_benign_timestamp, test_dga_years = (\n",
    "        testcase\n",
    "    )\n",
    "\n",
    "    Xtrain, ytrain = load_tranco(\n",
    "        scenario, benign_size=benign_size, dataset_timestamp=train_benign_timestamp\n",
    "    )\n",
    "    ytrain = pd.Series(ytrain).astype(int).astype(str)\n",
    "    ytrain[ytrain == \"0\"] = \"benign\"\n",
    "\n",
    "    Xtest, ytest = load_tranco(\n",
    "        scenario, benign_size=benign_size, dataset_timestamp=test_benign_timestamp\n",
    "    )\n",
    "    ytest = pd.Series(ytest).astype(int).astype(str)\n",
    "    ytest[ytest == \"0\"] = \"benign\"\n",
    "\n",
    "    Xmal_train, ymal_train = load_dgarchive(\n",
    "        scenario, dga_source_size=dga_size, years=train_dga_years\n",
    "    )\n",
    "    Xmal_test, ymal_test = load_dgarchive(\n",
    "        scenario, dga_source_size=dga_size, years=test_dga_years\n",
    "    )\n",
    "\n",
    "    # Xmal2, ymal2 = load_synthetic_dga(scenario, dga_source_size=dga_size)\n",
    "    # Xmal3, ymal3 = load_altered(scenario, dga_source_size=dga_size)\n",
    "\n",
    "    Xfull_train = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(Xtrain),\n",
    "            pd.DataFrame(Xmal_train),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    yfull_train = pd.concat(\n",
    "        [pd.Series(ytrain), pd.Series(ymal_train)],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    Xfull_test = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(Xtest),\n",
    "            pd.DataFrame(Xmal_test),\n",
    "            # pd.DataFrame(Xmal2),\n",
    "            # pd.DataFrame(Xmal3),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    yfull_test = pd.concat(\n",
    "        [\n",
    "            pd.Series(ytest),\n",
    "            pd.Series(ymal_test),\n",
    "            # pd.Series(ymal2),\n",
    "            # pd.Series(ymal3),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    return Xfull_train, yfull_train, Xfull_test, yfull_test\n",
    "\n",
    "\n",
    "def benchmark_dataset_2d(testname, X_train, y_train, X_test, y_test):\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "\n",
    "    y_train = pd.Series(y_train).astype(int).values\n",
    "    y_test = pd.Series(y_test).astype(int).values\n",
    "\n",
    "    train_hash = dataframe_hash(pd.DataFrame(X_train))\n",
    "    test_hash = dataframe_hash(pd.DataFrame(X_test))\n",
    "\n",
    "    best_results = None\n",
    "    best_f1 = -1\n",
    "\n",
    "    for model_name in MODELS_2D:\n",
    "        cache_file = WORKSPACE / f\"benchmarks_{testname}_{model_name}.bkp\"\n",
    "        if cache_file.exists():\n",
    "            scores = load_from_file(cache_file)\n",
    "\n",
    "            current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_results = scores\n",
    "\n",
    "    return best_results\n",
    "\n",
    "\n",
    "def _make_labels_binary(y):\n",
    "    y_bin = y.copy()\n",
    "    y_bin[y_bin != \"benign\"] = 1\n",
    "    y_bin[y_bin == \"benign\"] = 0\n",
    "\n",
    "    return y_bin\n",
    "\n",
    "\n",
    "def benchmark_binary(data_label, Xtrain, ytrain, Xtest, ytest):\n",
    "    ytrain_bin = _make_labels_binary(ytrain)\n",
    "    ytest_bin = _make_labels_binary(ytest)\n",
    "    return benchmark_dataset_2d(\n",
    "        f\"temporal_drift_{data_label}\", Xtrain, ytrain_bin, Xtest, ytest_bin\n",
    "    )\n",
    "\n",
    "\n",
    "SCENARIOS = [\"embs\", \"stats\"]\n",
    "\n",
    "SAMPLE_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4ae3d-9879-4c8f-b005-4e31d82ea550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scenario(data_label, scenario, testcase):\n",
    "    try:\n",
    "        Xtrain, ytrain, Xtest, ytest = load_dataset(\n",
    "            scenario=scenario,\n",
    "            benign_size=SAMPLE_SIZE,\n",
    "            dga_size=SAMPLE_SIZE,\n",
    "            testcase=testcase,\n",
    "        )\n",
    "    except BaseException:\n",
    "        print(\"scenario failed\", data_label)\n",
    "        return\n",
    "\n",
    "    return benchmark_binary(data_label, Xtrain, ytrain, Xtest, ytest)\n",
    "\n",
    "\n",
    "results_cache_file = Path(\"results/benchmark_temporal_drift.bkp\")\n",
    "if results_cache_file.exists():\n",
    "    all_results = load_from_file(results_cache_file)\n",
    "else:\n",
    "    all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bbaff7-36b0-48b2-a14d-84925d848e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for src_year in range(2007, 2024):\n",
    "    if src_year not in all_results:\n",
    "        all_results[src_year] = {}\n",
    "    for dst_year in range(src_year, 2024):\n",
    "        if dst_year in all_results[src_year]:\n",
    "            continue\n",
    "        train_benign_timestamp = \"2019-06-01\"\n",
    "        test_benign_timestamp = \"2023-12-01\"\n",
    "        train_dga_years = list(range(2006, src_year + 1))\n",
    "        test_dga_years = [dst_year]\n",
    "\n",
    "        if src_year == dst_year:\n",
    "            test_benign_timestamp = train_benign_timestamp\n",
    "\n",
    "        best_results = None\n",
    "        best_f1 = -1\n",
    "\n",
    "        for scenario in SCENARIOS:\n",
    "            data_label = f\"{scenario}_{train_benign_timestamp.replace('-', '_')}_{sum(train_dga_years)}_{test_benign_timestamp.replace('-', '_')}_{sum(test_dga_years)}\"\n",
    "            testcase = (\n",
    "                train_benign_timestamp,\n",
    "                train_dga_years,\n",
    "                test_benign_timestamp,\n",
    "                test_dga_years,\n",
    "            )\n",
    "            scores = test_scenario(data_label, scenario, testcase)\n",
    "            if scores is None:\n",
    "                continue\n",
    "            current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_results = scores\n",
    "        all_results[src_year][dst_year] = best_results\n",
    "        if best_results is None:\n",
    "            continue\n",
    "        print(src_year, dst_year, best_results[\"str\"][\"f1_score_macro\"])\n",
    "        save_to_file(results_cache_file, all_results)\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a82171-bcec-488c-96a1-f2b54ee965a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = []\n",
    "\n",
    "include_train_years = [2008, 2012, 2016, 2018]\n",
    "include_test_years = [2019, 2022, 2010, 2020]\n",
    "for src_year in all_results:\n",
    "    if src_year not in include_train_years:\n",
    "        continue\n",
    "    for dst_year in all_results[src_year]:\n",
    "        if all_results[src_year][dst_year] is None:\n",
    "            continue\n",
    "        if dst_year not in include_test_years and dst_year != src_year:\n",
    "            continue\n",
    "\n",
    "        f1_score = all_results[src_year][dst_year][\"raw\"][\"f1_score_macro\"][0]\n",
    "        f1_score_err = all_results[src_year][dst_year][\"raw\"][\"f1_score_macro\"][1]\n",
    "        mcc = all_results[src_year][dst_year][\"raw\"][\"mcc\"][0]\n",
    "        mcc_err = all_results[src_year][dst_year][\"raw\"][\"mcc\"][1]\n",
    "\n",
    "        results_df.append([src_year, dst_year, f1_score, f1_score_err, mcc, mcc_err])\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    results_df,\n",
    "    columns=[\n",
    "        \"Training Year\",\n",
    "        \"Test Year\",\n",
    "        \"F1 Score\",\n",
    "        \"F1 Score Error\",\n",
    "        \"MCC\",\n",
    "        \"MCC Error\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664aa27-b9a4-40cd-8349-5e9162b782e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from pathlib import Path\n",
    "\n",
    "# third party\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "DIAGRAMS = Path(\"diagrams\")\n",
    "DIAGRAMS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "FONT_SIZE = 18\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "custom_colors = prop_cycle.by_key()[\"color\"]\n",
    "custom_colors.extend(\n",
    "    [\n",
    "        \"#c5b0d5\",\n",
    "        \"#ffc500\",\n",
    "        \"#700548\",\n",
    "    ]\n",
    ")\n",
    "plt.figure(figsize=(7, 3))  # Keep the same figure size\n",
    "ax = plt.gca()\n",
    "plot = sns.lineplot(\n",
    "    data=results_df,\n",
    "    ax=ax,\n",
    "    x=\"Test Year\",\n",
    "    y=\"MCC\",\n",
    "    hue=\"Training Year\",\n",
    "    style=\"Training Year\",\n",
    "    markers=True,\n",
    "    palette=[\n",
    "        custom_colors[6],\n",
    "        custom_colors[3],\n",
    "        custom_colors[11],\n",
    "        custom_colors[0],\n",
    "        custom_colors[5],\n",
    "    ],\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Test Year\", fontsize=FONT_SIZE)\n",
    "plt.ylabel(\"MCC\", fontsize=FONT_SIZE)\n",
    "\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "figname = \"temporal_drift\"\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b0c55-c0bf-4f9f-bd68-06cad59cc683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dga",
   "language": "python",
   "name": "dga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
