# stdlib
from pathlib import Path

# third party
import numpy as np
import pandas as pd

# dga_analysis absolute
from dga_analysis.datasets.dataset_dgarchive import (
    DGA_ARITHMETIC,
    DGA_HASH,
    DGA_PERM,
    DGA_WORDLIST,
    FAMILIES,
)
from dga_analysis.datasets.dataset_mixed import DatasetMixed
from dga_analysis.detection.lr import LinearClassifier
from dga_analysis.detection.nn import NeuralNetClassifier
from dga_analysis.detection.rf import RFClassifier
from dga_analysis.detection.svm import SVMClassifier
from dga_analysis.detection.tree import DecisionTreeClassifier
from dga_analysis.detection.xgb import XGBoostClassifier
from dga_analysis.utils.evaluation import evaluate_classifier
from dga_analysis.utils.serialization import (
    dataframe_hash,
    load_from_file,
    save_to_file,
)

SAMPLE_SIZE = 150000
WORKSPACE = Path("workspace")
WORKSPACE.mkdir(parents=True, exist_ok=True)

MULTICLASS = False
SCENARIOS = ["stats", "embs"]

MODELS_2D = [
    "rf",
    "lr",
    # "svm",
    "xgb",
    "tree",
    "nn",
]


def load_model(model: str):
    if model == "rf":
        return RFClassifier()
    elif model == "lr":
        return LinearClassifier()
    elif model == "svm":
        return SVMClassifier()
    elif model == "xgb":
        return XGBoostClassifier()
    elif model == "tree":
        return DecisionTreeClassifier()
    elif model == "nn":
        return NeuralNetClassifier()


def load_dgarchive_family(families: list, scenario: str):
    dataset = DatasetMixed(
        sample_size=SAMPLE_SIZE,
        max_source_size=100,
        sources={"tranco": 0.5, "dgarchive": 0.5},
        multiclass=MULTICLASS,
        dga_families=families,
    )

    if scenario == "stats":
        return dataset.as_statistical(only_2ld=True)
    elif scenario == "embs":
        return dataset.as_embeddings(only_2ld=True)
    else:
        return dataset.raw(only_2ld=True)


def benchmark_family_2d(testname, scenario: str, X, y):
    data_hash = dataframe_hash(pd.DataFrame(X))

    for model_name in MODELS_2D:
        cache_file = (
            WORKSPACE
            / f"benchmarks_{model_name}_{data_hash}_{len(np.unique(y))}.v2.bkp"
        )
        if cache_file.exists():
            scores = load_from_file(cache_file)
            print(
                f"Test={testname}, repr={scenario}, #labels={len(np.unique(y))} model={model_name} scores={scores['str']}",
                flush=True,
            )
            continue

        try:
            model = load_model(model_name)
            scores = evaluate_classifier(model, X, y)
            save_to_file(cache_file, scores)
            print(
                f"Test={testname}, repr={scenario}, #labels={len(np.unique(y))} model={model_name} scores={scores['str']}",
                flush=True,
            )
        except BaseException as e:
            print("failed", testname, scenario, model_name, e, flush=True)
            continue


def benchmark_dgarchive_2d(testname, scenario, families):
    X, y = load_dgarchive_family(families, scenario=scenario)
    benchmark_family_2d(testname, scenario, X, y)


for scenario in SCENARIOS:
    benchmark_dgarchive_2d("ALL", scenario, FAMILIES)
    benchmark_dgarchive_2d("ARITHMETIC", scenario, DGA_ARITHMETIC)
    benchmark_dgarchive_2d("PERMUTATION", scenario, DGA_PERM)
    benchmark_dgarchive_2d("HASH", scenario, DGA_HASH)
    benchmark_dgarchive_2d("WORDLIST", scenario, DGA_WORDLIST)
