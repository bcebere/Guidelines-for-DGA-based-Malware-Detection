#!/usr/bin/env python
# coding: utf-8

# In[1]:


# stdlib
from pathlib import Path
from random import shuffle

# third party
import numpy as np
import pandas as pd
from joblib import Parallel, delayed

# dga_analysis absolute
from dga_analysis.datasets.dataset_altered_benign import STRATEGIES
from dga_analysis.datasets.dataset_dgarchive import FAMILIES as DGA_FAMILIES
from dga_analysis.datasets.dataset_mixed import DatasetMixed
from dga_analysis.datasets.dataset_synthetic_dga import FAMILIES as SYN_FAMILIES
from dga_analysis.datasets.dataset_tranco import TYPOS, DatasetTranco
from dga_analysis.detection.cnn import CNNClassifier
from dga_analysis.detection.ji import JIClassifier
from dga_analysis.detection.lr import LinearClassifier
from dga_analysis.detection.nn import NeuralNetClassifier
from dga_analysis.detection.recurrent import (
    GRUClassifier,
    LSTMClassifier,
    RNNClassifier,
)
from dga_analysis.detection.rescnn import ResCNNClassifier
from dga_analysis.detection.rf import RFClassifier
from dga_analysis.detection.svm import SVMClassifier
from dga_analysis.detection.transformer import TransformerClassifier
from dga_analysis.detection.tree import DecisionTreeClassifier
from dga_analysis.detection.xgb import XGBoostClassifier
from dga_analysis.utils.serialization import (
    dataframe_hash,
    load_from_file,
    save_to_file,
)

SAMPLE_SIZE = 40000
DGA_SUBSAMPLES = 20000
WORKSPACE = Path("workspace_typo")
WORKSPACE.mkdir(parents=True, exist_ok=True)

MULTICLASS = False
MODELS_2D = [
    "rf",
    # "lr",
    # "svm",
    "xgb",
    # "tree",
    # "nn",
]

MODELS_3D = [
    # "rnn",
    # "lstm",
    # "gru",
    # "transformer",
    # "cnn",
    # "rescnn",
    # "ji",
]

TEST_SIZE = 20000
BENIGN_SUBSAMPLES = [20000]
TEST_DATA = {}

full_testdata_bkp = WORKSPACE / f"tranco_simple_typo_all_{TEST_SIZE}.v4.bkp"

if full_testdata_bkp.exists():
    TEST_DATA = load_from_file(full_testdata_bkp)
else:
    for typo in TYPOS + [None]:
        if typo is None:
            typo_data = DatasetTranco(sample_size=TEST_SIZE, shuffle=False, typos=[])
        else:
            testdata_bkp = WORKSPACE / f"tranco_simple_typo_{typo}_{TEST_SIZE}.v3.bkp"
            if testdata_bkp.exists():
                typo_data = load_from_file(testdata_bkp)
            else:
                typo_data = DatasetTranco(
                    sample_size=TEST_SIZE, shuffle=False, typos=[typo]
                )
                save_to_file(testdata_bkp, typo_data)
        test_raw, _ = typo_data.raw_np(only_2ld=True)
        test_embs, _ = typo_data.as_embeddings(only_2ld=True)
        print(typo, test_raw[:10])
        # test_stats, _ = typo_data.as_statistical(only_2ld=True)
        TEST_DATA[typo] = {
            "raw": test_raw,
            "embs": test_embs,
            # "stats" : test_stats,
        }
    save_to_file(full_testdata_bkp, TEST_DATA)


def load_model(model: str):
    if model == "rf":
        return RFClassifier()
    elif model == "lr":
        return LinearClassifier()
    elif model == "svm":
        return SVMClassifier()
    elif model == "xgb":
        return XGBoostClassifier()
    elif model == "tree":
        return DecisionTreeClassifier()
    elif model == "nn":
        return NeuralNetClassifier(
            n_layers_hidden=2,
            n_units_hidden=200,
            dropout=0.1,
            n_iter=1000,
        )
    elif model == "cnn":
        return CNNClassifier(
            n_units_emb=256,
            n_iter=1000,
        )
    elif model == "ji":
        return JIClassifier()
    elif model == "transformer":
        return TransformerClassifier(
            n_layers=2,
            n_units_emb=200,
            dropout=0.1,
            n_iter=1000,
        )
    elif model == "lstm":
        return LSTMClassifier(
            n_layers=2,
            n_units_emb=200,
            n_units_hidden=200,
            dropout=0,
            n_iter=1000,
        )
    elif model == "rnn":
        return RNNClassifier(
            n_layers=2,
            n_units_emb=200,
            n_units_hidden=200,
            dropout=0.1,
            n_iter=1000,
        )
    elif model == "gru":
        return GRUClassifier(
            n_layers=2,
            n_units_emb=200,
            n_units_hidden=200,
            dropout=0.1,
            n_iter=1000,
        )
    elif model == "rescnn":
        return ResCNNClassifier(
            n_units_emb=256,
            dropout=0.1,
            n_iter=1000,
        )
    else:
        raise NotImplementedError(model)


def load_dgarchive_family(
    family: str,
    scenario: str,
    max_benign_source: int = 100000,
    max_dga_source: int = 100000,
):
    dataset = DatasetMixed(
        sample_size=SAMPLE_SIZE,
        sources={"tranco": 0.5, "dgarchive": 0.5},
        multiclass=MULTICLASS,
        dga_families=[family],
        max_benign_source=max_benign_source,
        max_dga_source=max_dga_source,
        shuffle=False,
    )

    if scenario == "stats":
        return dataset.as_statistical(only_2ld=True)
    elif scenario == "embs":
        return dataset.as_embeddings(only_2ld=True)
    else:
        return dataset.raw(only_2ld=True)


def benchmark_family_2d(typo: str, family: str, scenario: str, X, y):
    if scenario == "raw":
        models = MODELS_3D
        Xtest = TEST_DATA[typo]["raw"]
    elif scenario == "embs":
        models = MODELS_2D
        Xtest = TEST_DATA[typo]["embs"]
    else:
        models = MODELS_2D
        Xtest = TEST_DATA[typo]["stats"]

    X = np.asarray(X)

    data_hash = dataframe_hash(pd.DataFrame(X))

    for model_name in models:
        cache_file = (
            WORKSPACE
            / f"benchmarks_typo_{typo}_{model_name}_{data_hash}_{TEST_SIZE}.v3.bkp"
        )
        if cache_file.exists():
            scores = load_from_file(cache_file)
            print(
                "cached",
                family,
                typo,
                model_name,
                np.sum(scores),
                flush=True,
            )
            continue

        try:
            model = load_model(model_name)
            model.fit(X, y)
            scores = model.predict(Xtest)
            print(
                "computed",
                family,
                typo,
                model_name,
                np.sum(scores),
                flush=True,
            )
            save_to_file(cache_file, scores)
        except BaseException as e:
            print("failed", family, model_name, e, flush=True)
            continue


def benchmark_dgarchive_2d(
    typo: str,
    family: str,
    scenario: str,
    max_benign_source: int = 100000,
    max_dga_source: int = 100000,
):
    X, y = load_dgarchive_family(
        family,
        scenario=scenario,
        max_benign_source=max_benign_source,
        max_dga_source=max_dga_source,
    )
    benchmark_family_2d(typo, family, scenario, X, y)


def load_synthetic_family(
    family: str,
    scenario: str = "stats",
    max_benign_source: int = 100000,
    max_dga_source: int = 10000,
):  # stats, embs, raw
    dataset = DatasetMixed(
        sample_size=SAMPLE_SIZE,
        sources={"tranco": 0.5, "synthetic_dga": 0.5},
        multiclass=MULTICLASS,
        dga_families=[family],
        max_benign_source=max_benign_source,
        max_dga_source=max_dga_source,
        shuffle=False,
    )

    if scenario == "stats":
        return dataset.as_statistical(only_2ld=True)
    elif scenario == "embs":
        return dataset.as_embeddings(only_2ld=True, max_length=100)
    else:
        return dataset.raw(only_2ld=True)


def benchmark_synthetic(
    typo: str,
    family: str,
    scenario: str,
    max_benign_source: int = 100000,
    max_dga_source: int = 10000,
):
    X, y = load_synthetic_family(
        family,
        scenario=scenario,
        max_benign_source=max_benign_source,
        max_dga_source=max_dga_source,
    )
    benchmark_family_2d(typo, family, scenario, X, y)


def load_altered_family(
    strategy: str, scenario: str, max_benign_source: int, max_dga_source: int
):
    dataset = DatasetMixed(
        sample_size=SAMPLE_SIZE,
        sources={"tranco": 0.5, "altered_benign": 0.5},
        dga_families=[strategy],
        max_benign_source=max_benign_source,
        max_dga_source=max_dga_source,
        shuffle=False,
    )

    if scenario == "stats":
        return dataset.as_statistical(only_2ld=True)
    elif scenario == "embs":
        return dataset.as_embeddings(only_2ld=True)
    else:
        return dataset.raw(only_2ld=True)


def benchmark_altered_2d(
    typo: str,
    strategy: str,
    scenario: str,
    max_benign_source: int = 100000,
    max_dga_source: int = 100000,
):
    X, y = load_altered_family(
        strategy,
        scenario=scenario,
        max_benign_source=max_benign_source,
        max_dga_source=max_dga_source,
    )
    benchmark_family_2d(typo, strategy, scenario, X, y)


SCENARIOS = ["embs", "raw"]
parallel = Parallel(n_jobs=10)

for typo in TYPOS:
    for benign_size in BENIGN_SUBSAMPLES:
        for scenario in SCENARIOS:
            for strategy in STRATEGIES:
                benchmark_altered_2d(
                    typo,
                    strategy,
                    scenario=scenario,
                    max_benign_source=benign_size,
                    max_dga_source=DGA_SUBSAMPLES,
                )


shuffle(SYN_FAMILIES)
shuffle(SYN_FAMILIES)
results = parallel(
    delayed(benchmark_synthetic)(
        typo,
        family,
        scenario=scenario,
        max_benign_source=benign_size,
        max_dga_source=DGA_SUBSAMPLES,
    )
    for family in SYN_FAMILIES
    for scenario in SCENARIOS
    for benign_size in BENIGN_SUBSAMPLES
    for typo in TYPOS
)

shuffle(DGA_FAMILIES)
shuffle(DGA_FAMILIES)
results = parallel(
    delayed(benchmark_dgarchive_2d)(
        typo,
        family,
        scenario=scenario,
        max_benign_source=benign_size,
        max_dga_source=DGA_SUBSAMPLES,
    )
    for family in DGA_FAMILIES
    for scenario in SCENARIOS
    for benign_size in BENIGN_SUBSAMPLES
    for typo in TYPOS
)
