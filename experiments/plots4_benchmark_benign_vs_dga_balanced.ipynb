{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd46bc-f276-4e27-97cf-a05b34362175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# stdlib\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from tldextract import extract\n",
    "\n",
    "# dga_analysis absolute\n",
    "from dga_analysis.datasets.dataset_altered_benign import STRATEGIES, DatasetAltered\n",
    "from dga_analysis.datasets.dataset_dgarchive import FAMILIES as DGA_FAMILIES\n",
    "from dga_analysis.datasets.dataset_mixed import DatasetMixed\n",
    "from dga_analysis.datasets.dataset_synthetic_dga import FAMILIES as SYN_FAMILIES\n",
    "from dga_analysis.detection.cnn import CNNClassifier\n",
    "from dga_analysis.detection.ji import JIClassifier\n",
    "from dga_analysis.detection.knn import KNNClassifier\n",
    "from dga_analysis.detection.lr import LinearClassifier\n",
    "from dga_analysis.detection.nn import NeuralNetClassifier\n",
    "from dga_analysis.detection.recurrent import (\n",
    "    GRUClassifier,\n",
    "    LSTMClassifier,\n",
    "    RecurrentClassifier,\n",
    "    RNNClassifier,\n",
    ")\n",
    "from dga_analysis.detection.rescnn import ResCNNClassifier\n",
    "from dga_analysis.detection.rf import RFClassifier\n",
    "from dga_analysis.detection.svm import SVMClassifier\n",
    "from dga_analysis.detection.transformer import TransformerClassifier\n",
    "from dga_analysis.detection.tree import DecisionTreeClassifier\n",
    "from dga_analysis.detection.xgb import XGBoostClassifier\n",
    "from dga_analysis.utils.evaluation import evaluate_classifier\n",
    "from dga_analysis.utils.features.examples import ALL\n",
    "from dga_analysis.utils.serialization import (\n",
    "    dataframe_hash,\n",
    "    load_from_file,\n",
    "    save_to_file,\n",
    ")\n",
    "\n",
    "SAMPLE_SIZE = 150000\n",
    "BENIGN_SUBSAMPLES = 20000\n",
    "DGA_SUBSAMPLES = 20000\n",
    "\n",
    "WORKSPACE = Path(\"workspace\")\n",
    "WORKSPACE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DIAGRAMS = Path(\"diagrams\")\n",
    "DIAGRAMS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MULTICLASS = False\n",
    "\n",
    "MODELS_2D = [\n",
    "    \"rf\",\n",
    "    \"lr\",\n",
    "    # \"svm\",\n",
    "    \"xgb\",\n",
    "    \"tree\",\n",
    "    # \"nn\",\n",
    "]\n",
    "\n",
    "MODELS_3D = [\n",
    "    # \"rnn\",\n",
    "    \"lstm\",\n",
    "    # \"gru\",\n",
    "    \"transformer\",\n",
    "    \"cnn\",\n",
    "    \"rescnn\",\n",
    "    # \"ji\",\n",
    "]\n",
    "SCENARIOS = [\"raw\", \"embs\", \"stats\"]\n",
    "\n",
    "\n",
    "def load_model(model: str):\n",
    "    if model == \"rf\":\n",
    "        return RFClassifier()\n",
    "    elif model == \"lr\":\n",
    "        return LinearClassifier()\n",
    "    elif model == \"svm\":\n",
    "        return SVMClassifier()\n",
    "    elif model == \"xgb\":\n",
    "        return XGBoostClassifier()\n",
    "    elif model == \"tree\":\n",
    "        return DecisionTreeClassifier()\n",
    "    elif model == \"nn\":\n",
    "        return NeuralNetClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"cnn\":\n",
    "        return CNNClassifier(\n",
    "            n_units_emb=256,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"ji\":\n",
    "        return JIClassifier()\n",
    "    elif model == \"transformer\":\n",
    "        return TransformerClassifier(\n",
    "            n_layers=1,\n",
    "            n_units_emb=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"lstm\":\n",
    "        return LSTMClassifier(\n",
    "            n_layers=1,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"rnn\":\n",
    "        return RNNClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"gru\":\n",
    "        return GRUClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"rescnn\":\n",
    "        return ResCNNClassifier(\n",
    "            n_units_emb=256,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplemented(model)\n",
    "\n",
    "\n",
    "def load_dgarchive_family(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"dgarchive\": 0.5},\n",
    "        multiclass=MULTICLASS,\n",
    "        dga_families=[family],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    # print(\"load\", family, scenario, max_benign_source, max_dga_source)\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def load_altered_family(\n",
    "    altered: str, scenario: str, max_benign_source: int, max_dga_source: int\n",
    "):\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"altered_benign\": 0.5},\n",
    "        dga_families=[strategy],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def load_synthetic_family(\n",
    "    family: str,\n",
    "    scenario: str = \"stats\",\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 10000,\n",
    "):  # stats, embs, raw\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"synthetic_dga\": 0.5},\n",
    "        multiclass=MULTICLASS,\n",
    "        dga_families=[family],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True, max_length=100)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def get_results_family_2d(family: str, scenario: str, X, y):\n",
    "    if scenario == \"raw\":\n",
    "        models = MODELS_3D\n",
    "    else:\n",
    "        models = MODELS_2D\n",
    "    X = np.asarray(X)\n",
    "\n",
    "    data_hash = dataframe_hash(pd.DataFrame(X))\n",
    "\n",
    "    best_results = None\n",
    "    best_f1 = -1\n",
    "    for model_name in models:\n",
    "        cache_file = (\n",
    "            WORKSPACE\n",
    "            / f\"benchmarks_{model_name}_{data_hash}_{len(np.unique(y))}.v2.bkp\"\n",
    "        )\n",
    "        if cache_file.exists():\n",
    "            scores = load_from_file(cache_file)\n",
    "            current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_results = scores\n",
    "\n",
    "            # print(\"FOUND \", family, model_name, cache_file)\n",
    "\n",
    "            # print(\n",
    "            #     family,\n",
    "            #     model_name,\n",
    "            #     scenario,\n",
    "            #     pd.Series(y).value_counts().to_dict(),\n",
    "            #     scores[\"str\"],\n",
    "            #     flush=True,\n",
    "            # )\n",
    "            continue\n",
    "\n",
    "    return best_results\n",
    "\n",
    "\n",
    "def benchmark_dgarchive_2d(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    X, y = load_dgarchive_family(\n",
    "        family,\n",
    "        scenario=scenario,\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    return get_results_family_2d(family, scenario, X, y)\n",
    "\n",
    "\n",
    "def benchmark_synthetic(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 10000,\n",
    "):\n",
    "    X, y = load_synthetic_family(\n",
    "        family,\n",
    "        scenario=scenario,\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    return get_results_family_2d(family, scenario, X, y)\n",
    "\n",
    "\n",
    "def benchmark_altered_2d(\n",
    "    strategy: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    X, y = load_altered_family(\n",
    "        strategy,\n",
    "        scenario=scenario,\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    return get_results_family_2d(strategy, scenario, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7986fd-b136-4cee-b40b-88b734cdbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60600b-6f31-488f-b8f6-87beac74a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family in DGA_FAMILIES:\n",
    "    best_results = None\n",
    "    best_f1 = -1\n",
    "\n",
    "    for scenario in SCENARIOS:\n",
    "        scores = benchmark_dgarchive_2d(\n",
    "            family,\n",
    "            scenario=scenario,\n",
    "            max_benign_source=BENIGN_SUBSAMPLES,\n",
    "            max_dga_source=DGA_SUBSAMPLES,\n",
    "        )\n",
    "        if scores is None:\n",
    "            continue\n",
    "        current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_results = scores\n",
    "    if best_results is None:\n",
    "        print(\"missing results\", family)\n",
    "        continue\n",
    "    print(family, best_results[\"str\"][\"f1_score_macro\"])\n",
    "    all_results[family] = best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d47430-06e6-4d1f-b532-f31a3a965ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family in SYN_FAMILIES:\n",
    "    best_results = None\n",
    "    best_f1 = -1\n",
    "\n",
    "    for scenario in SCENARIOS:\n",
    "        scores = benchmark_synthetic(\n",
    "            family,\n",
    "            scenario=scenario,\n",
    "            max_benign_source=BENIGN_SUBSAMPLES,\n",
    "            max_dga_source=DGA_SUBSAMPLES,\n",
    "        )\n",
    "        if scores is None:\n",
    "            continue\n",
    "        current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_results = scores\n",
    "\n",
    "    if best_results is None:\n",
    "        print(\"missing results\", family)\n",
    "        continue\n",
    "    print(family, best_results[\"str\"][\"f1_score_macro\"])\n",
    "    all_results[family] = best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0536f4-92ad-4766-9285-1c5c0fe9fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for strategy in STRATEGIES:\n",
    "    best_results = None\n",
    "    best_f1 = -1\n",
    "\n",
    "    for scenario in SCENARIOS:\n",
    "        scores = benchmark_altered_2d(\n",
    "            strategy,\n",
    "            scenario=scenario,\n",
    "            max_benign_source=BENIGN_SUBSAMPLES,\n",
    "            max_dga_source=DGA_SUBSAMPLES,\n",
    "        )\n",
    "        if scores is None:\n",
    "            continue\n",
    "        current_f1 = scores[\"raw\"][\"f1_score_macro\"][0]\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_results = scores\n",
    "\n",
    "    if best_results is None:\n",
    "        print(\"missing results\", family)\n",
    "        continue\n",
    "    print(strategy, best_results[\"str\"][\"f1_score_macro\"])\n",
    "    all_results[strategy] = best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e993a-f972-4589-a797-a653d7ac67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92708311-5ccf-4e11-b40f-ba2848ef6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_to_file(\"results/benchmarks_benign_vs_singledga.bkp\", all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061be93d-75e1-4917-9b6f-73022716bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_results = load_from_file(\"results/benchmarks_benign_vs_singledga.bkp\")\n",
    "\n",
    "len(cached_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11705b72-e482-4116-8100-4b5a8f1c5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "precision = []\n",
    "recall = []\n",
    "mcc = []\n",
    "full_scores = []\n",
    "full_mcc_scores = []\n",
    "families = []\n",
    "\n",
    "minval = 0.4\n",
    "for family in cached_results:\n",
    "\n",
    "    f1_scores.append(max(minval, cached_results[family][\"raw\"][\"f1_score_macro\"][0]))\n",
    "    precision.append(max(minval, cached_results[family][\"raw\"][\"precision_macro\"][0]))\n",
    "    recall.append(max(minval, cached_results[family][\"raw\"][\"recall_macro\"][0]))\n",
    "    mcc.append(cached_results[family][\"raw\"][\"mcc\"][0])\n",
    "    families.append(family)\n",
    "\n",
    "    full_scores.extend(\n",
    "        [\n",
    "            [\n",
    "                \"F1 Score\",\n",
    "                max(minval, cached_results[family][\"raw\"][\"f1_score_macro\"][0]),\n",
    "            ],\n",
    "            [\n",
    "                \"Precision\",\n",
    "                max(minval, cached_results[family][\"raw\"][\"precision_macro\"][0]),\n",
    "            ],\n",
    "            [\"Recall\", max(minval, cached_results[family][\"raw\"][\"recall_macro\"][0])],\n",
    "            # [\"MCC\", max(minval, cached_results[family][\"raw\"][\"mcc\"][0])],\n",
    "        ]\n",
    "    )\n",
    "    full_mcc_scores.extend(\n",
    "        [\n",
    "            [\"MCC\", cached_results[family][\"raw\"][\"mcc\"][0]],\n",
    "        ]\n",
    "    )\n",
    "metrics = pd.DataFrame(\n",
    "    {\n",
    "        \"Family\": families,\n",
    "        \"F1 Score\": f1_scores,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"MCC\": mcc,\n",
    "    }\n",
    ")\n",
    "\n",
    "full_scores = pd.DataFrame(full_scores, columns=[\"Metric\", \"Score\"])\n",
    "full_mcc_scores = pd.DataFrame(full_mcc_scores, columns=[\"Metric\", \"Score\"])\n",
    "full_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4922f129-7500-46e0-a86d-78a4b85894c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metrics[metrics[\"F1 Score\"] <= 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19d01b-d7d3-4755-82ef-e5f46544ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_score(metric: np.ndarray):\n",
    "    percentile_val = 1.96\n",
    "    # metric_mean = np.mean(metric)\n",
    "    # metric_5per = np.percentile(metric, 5)\n",
    "    # err = metric_mean - metric_5per\n",
    "    return (\n",
    "        np.mean(metric),\n",
    "        np.std(metric),\n",
    "    )  # percentile_val * np.std(metric) / np.sqrt(len(metric)))\n",
    "\n",
    "\n",
    "def print_score(score) -> str:\n",
    "    return str(round(score[0], 3)) + \" +/- \" + str(round(score[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073e46e-c526-4199-ae6d-e2fed1995646",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = []\n",
    "\n",
    "for metric in [\"F1 Score\", \"Recall\", \"Precision\", \"MCC\"]:\n",
    "    pretty_score = print_score(generate_score(metrics[metric].values))\n",
    "    min_score = round(metrics[metric].min(), 3)\n",
    "    max_score = round(metrics[metric].max(), 3)\n",
    "    median_score = round(metrics[metric].median(), 3)\n",
    "\n",
    "    metrics_table.append([metric, pretty_score, min_score, median_score, max_score])\n",
    "\n",
    "metrics_table = pd.DataFrame(\n",
    "    metrics_table,\n",
    "    columns=[\n",
    "        \"Metric\",\n",
    "        \"Avg.\",\n",
    "        \"Min\",\n",
    "        \"Median\",\n",
    "        \"Max\",\n",
    "    ],\n",
    ")  # .set_index(\"Metric\")\n",
    "\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938cca93-a90e-4d4e-869a-815e246d4a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score(metrics[\"MCC\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4c2f0-525e-49bb-a0f6-a51627a0b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"F1 Score\"].sort_values().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0074038-dd79-4181-a290-23aeb07d4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# libraries & dataset\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "FONT_SIZE = 18\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "custom_colors = prop_cycle.by_key()[\"color\"]\n",
    "custom_colors.extend(\n",
    "    [\n",
    "        \"#c5b0d5\",\n",
    "        \"#ffc500\",\n",
    "        \"#700548\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def format_func(value, tick_number):\n",
    "    return f\"{value:.1f}\"\n",
    "\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(\n",
    "    1, 2, figsize=(7, 3), gridspec_kw={\"width_ratios\": [3, 1]}\n",
    ")\n",
    "\n",
    "# plt.figure(figsize=(7,3))\n",
    "# ax = plt.gca()\n",
    "\n",
    "hue_palette = [\n",
    "    custom_colors[0],\n",
    "    custom_colors[1],\n",
    "    custom_colors[3],\n",
    "    custom_colors[11],\n",
    "]\n",
    "hatches = [\"/////\", \"\\\\\\\\\\\\\\\\\\\\\", \"|||||\", \"xxxx\"]\n",
    "\n",
    "bp = sns.boxplot(\n",
    "    x=full_scores[\"Metric\"],\n",
    "    y=full_scores[\"Score\"],\n",
    "    hue=full_scores[\"Metric\"],\n",
    "    palette=hue_palette,\n",
    "    # color = custom_colors[1],\n",
    "    # linecolor =  custom_colors[1],\n",
    "    fliersize=7,\n",
    "    # flierprops={ \"marker\": \"o\",  \"markeredgecolor\": custom_colors[3], \"color\": \"white\", \"markerfacecolor\": custom_colors[3], \"alpha\": 0.2},\n",
    "    boxprops={\"facecolor\": \"none\", \"linewidth\": 2, \"alpha\": 0.9, \"hatch\": \"//////\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"solid\"},\n",
    "    meanline=True,\n",
    "    showmeans=True,\n",
    "    meanprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"dashdot\"},\n",
    "    ax=ax0,\n",
    ")\n",
    "for i, bar in enumerate(bp.patches):\n",
    "    if not isinstance(bar, matplotlib.patches.PathPatch):\n",
    "        continue\n",
    "    bar.set_hatch(hatches[int(i)])\n",
    "    bar.set_edgecolor(hue_palette[int(i)])\n",
    "\n",
    "bp = sns.boxplot(\n",
    "    x=full_mcc_scores[\"Metric\"],\n",
    "    y=full_mcc_scores[\"Score\"],\n",
    "    # hue = full_mcc_scores[\"Metric\"],\n",
    "    palette=[custom_colors[11]],\n",
    "    color=custom_colors[11],\n",
    "    fliersize=7,\n",
    "    boxprops={\"facecolor\": \"none\", \"linewidth\": 2, \"alpha\": 0.9, \"hatch\": \"//////\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"solid\"},\n",
    "    meanline=True,\n",
    "    showmeans=True,\n",
    "    meanprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"dashdot\"},\n",
    "    ax=ax1,\n",
    ")\n",
    "for i, bar in enumerate(bp.patches):\n",
    "    if not isinstance(bar, matplotlib.patches.PathPatch):\n",
    "        continue\n",
    "    bar.set_hatch(\"xxxx\")\n",
    "    bar.set_edgecolor(custom_colors[11])\n",
    "\n",
    "# ax0.set_xlabel(\"Performance Metric\", fontsize = FONT_SIZE)\n",
    "fig.text(0.55, -0.05, \"Performance Metric\", fontsize=FONT_SIZE, ha=\"center\")\n",
    "ax0.set_ylabel(\"Score\", fontsize=FONT_SIZE)\n",
    "ax1.set_ylabel(None)\n",
    "ax1.set_xlabel(None)\n",
    "ax0.set_xlabel(None)\n",
    "\n",
    "ax0.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax0.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "ax1.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax1.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "\n",
    "\n",
    "# ax0.vlines(x=3.5, ymin=min(full_scores[\"Score\"]), ymax=max(full_scores[\"Score\"]), color = 'r')\n",
    "\n",
    "arrow_props = dict(arrowstyle=\"<|-|>\", color=\"black\", linewidth=1)\n",
    "arrow_xpos = 1.05\n",
    "linecolor = \"black\"  # custom_colors[7]\n",
    "\n",
    "ax1.text(0.7, 0.8, \"easy\", color=linecolor, fontsize=14, ha=\"center\", rotation=90)\n",
    "ax1.text(0.7, 0.1, \"difficult\", color=linecolor, fontsize=14, ha=\"center\", rotation=90)\n",
    "\n",
    "ax1.annotate(\n",
    "    \"\",\n",
    "    xy=(arrow_xpos, 1),\n",
    "    xytext=(arrow_xpos, 0),\n",
    "    arrowprops=arrow_props,\n",
    "    xycoords=(\"axes fraction\", \"data\"),\n",
    "    textcoords=(\"axes fraction\", \"data\"),\n",
    ")\n",
    "ax1.annotate(\n",
    "    \"\",\n",
    "    xy=(arrow_xpos, 1),\n",
    "    xytext=(arrow_xpos, 0),\n",
    "    arrowprops=arrow_props,\n",
    "    xycoords=(\"axes fraction\", \"data\"),\n",
    "    textcoords=(\"axes fraction\", \"data\"),\n",
    ")\n",
    "\n",
    "ax0.yaxis.set_major_formatter(ticker.FuncFormatter(format_func))\n",
    "ax1.yaxis.set_major_formatter(ticker.FuncFormatter(format_func))\n",
    "\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "figname = \"benchmarks_benign_vs_dga\"\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6ea79-15a3-455e-8718-64e63b1491f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5db03e-031a-43f6-85ab-5f716c0106ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dga",
   "language": "python",
   "name": "dga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
