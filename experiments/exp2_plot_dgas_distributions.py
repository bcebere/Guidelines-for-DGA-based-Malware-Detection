# stdlib
import warnings
from pathlib import Path
from random import shuffle

# third party
import numpy as np
import pandas as pd
from joblib import Parallel, delayed
from sklearn.manifold import TSNE
from sklearn.preprocessing import MinMaxScaler

# dga_analysis absolute
from dga_analysis.datasets.dataset_dgarchive import FAMILIES, DatasetDGArchive
from dga_analysis.datasets.dataset_synthetic_dga import DatasetSyntheticDGA
from dga_analysis.utils.serialization import dataframe_hash

warnings.filterwarnings("ignore")

SAMPLE_SIZE = 50000
only_2ld = True

FILTERED_COLS = [
    "domain-name-length",
    "contains-digits",
    "end-digit-edge-distance",
    "start-digit-edge-distance",
    "inverse-hamming-distance",
    "consonants-max-streak-length",
    "decimaldigits-max-streak-length",
    "hexadecimaldigits-max-streak-length",
    "primedigits-max-streak-length",
    "hyphens-max-streak-length",
    "vowels-max-streak-length",
    "syllable-count",
    "bits-entropy",
    "binary-matrix-rank-test",
    "longest-run-of-ones-test",
    "adjacent-duplicates-ratio",
    "alphabet-hyphen",
    "alphabet-0",
    "alphabet-1",
    "alphabet-2",
    "alphabet-3",
    "alphabet-4",
    "alphabet-5",
    "alphabet-6",
    "alphabet-7",
    "alphabet-8",
    "alphabet-9",
    "alphabet-a",
    "alphabet-b",
    "alphabet-c",
    "alphabet-d",
    "alphabet-e",
    "alphabet-f",
    "alphabet-g",
    "alphabet-h",
    "alphabet-i",
    "alphabet-j",
    "alphabet-k",
    "alphabet-l",
    "alphabet-m",
    "alphabet-n",
    "alphabet-o",
    "alphabet-p",
    "alphabet-q",
    "alphabet-r",
    "alphabet-s",
    "alphabet-t",
    "alphabet-u",
    "alphabet-v",
    "alphabet-w",
    "alphabet-x",
    "alphabet-y",
    "alphabet-z",
    "consonants-character-ratio",
    "decimaldigits-character-ratio",
    "hexadecimaldigits-character-ratio",
    "hyphens-character-ratio",
    "primedigits-character-ratio",
    "vowels-character-ratio",
    "underscore-character-ratio",
    "consecutive-consonant-ratio",
    "consecutive-digit-ratio",
    "suffix-digit-sum",
    "first-character-pair",
    "repeated-characters-ratio",
    "suffix-standard-deviation",
    "weighted-streaks",
    "1-gram-alphabet-diversity",
    "1-gram-alphabet-size",
    "1-gram-arithmetic-mean",
    "1-gram-harmonic-mean",
    "1-gram-kurtosis",
    "1-gram-lower-quartile",
    "1-gram-max",
    "1-gram-median",
    "1-gram-min",
    "1-gram-shannon-entropy",
    "1-gram-skewness",
    "1-gram-standard-deviation",
    "1-gram-upper-quartile",
    "2-gram-alphabet-diversity",
    "2-gram-alphabet-size",
    "2-gram-arithmetic-mean",
    "2-gram-harmonic-mean",
    "2-gram-kurtosis",
    "2-gram-lower-quartile",
    "2-gram-max",
    "2-gram-median",
    "2-gram-min",
    "2-gram-shannon-entropy",
    "2-gram-skewness",
    "2-gram-standard-deviation",
    "2-gram-upper-quartile",
]


WORKSPACE = Path("workspace")
WORKSPACE.mkdir(parents=True, exist_ok=True)

fontsize = 18


def load_dgarchive_family(family: str):
    dataset_mal = DatasetDGArchive(
        sample_size=SAMPLE_SIZE,
        max_source_size=SAMPLE_SIZE,
        families=[family],
    )

    X_mal, _ = dataset_mal.as_statistical(only_2ld=only_2ld)
    return X_mal


def load_synthetic_family(family: str):
    dataset_mal = DatasetSyntheticDGA(
        sample_size=SAMPLE_SIZE,
        max_source_size=SAMPLE_SIZE,
        families=[family],
    )

    X_mal, _ = dataset_mal.as_statistical(only_2ld=only_2ld)
    return X_mal


def load_all_dgarchive_families():
    dataset_mal = DatasetDGArchive(
        sample_size=SAMPLE_SIZE,
        max_source_size=SAMPLE_SIZE,
    )

    X_mal, _ = dataset_mal.as_statistical(only_2ld=only_2ld)
    return X_mal


def fit_tsne(data):
    data = pd.DataFrame(data)
    cache_file = WORKSPACE / f"dgatsne_cache_{dataframe_hash(data)}.bkp"

    if cache_file.exists():
        try:
            proj = pd.read_csv(cache_file)
            return np.asarray(proj)
        except BaseException:
            pass

    tsne = TSNE(n_components=2, random_state=0, init="random")
    proj = pd.DataFrame(tsne.fit_transform(data))
    proj.to_csv(cache_file, index=None)

    return np.asarray(proj)


def plot_tsne(
    left_data,
    left_label: str,
    right_data,
    right_label: str,
    right_bullet_alpha=0.5,
    right_bullet_size=2,
):
    fit_tsne(right_data)
    fit_tsne(left_data)


def process_dgarchive_family(family: str):
    # dga_analysis absolute
    from dga_analysis.datasets.dataset_dgarchive import FAMILIES

    other_fams = FAMILIES[:]
    other_fams.remove(family)
    assert family in FAMILIES
    try:
        dataset_mal = DatasetDGArchive(
            sample_size=SAMPLE_SIZE,
            max_source_size=SAMPLE_SIZE,
            families=[family],
        )
        dataset_other = DatasetDGArchive(
            sample_size=SAMPLE_SIZE,
            max_source_size=1000,
            families=other_fams,
        )
        print(
            "evaluate family", family, len(dataset_mal), len(dataset_other), flush=True
        )

        X_mal, _ = dataset_mal.as_statistical(only_2ld=only_2ld)
        X_other, _ = dataset_other.as_statistical(only_2ld=only_2ld)

        X_mal = np.asarray(X_mal[FILTERED_COLS])
        X_other = np.asarray(X_other[FILTERED_COLS])

        scaler = MinMaxScaler().fit(X_other)
        X_mal = scaler.transform(X_mal)
        X_other = scaler.transform(X_other)
        plot_tsne(
            X_other,
            f"DGArchive \\ {family}",
            X_mal,
            f"DGA: {family}",
        )
    except BaseException as e:
        print("family failed", family, e, flush=True)


# ## Process DGArchive families
shuffle(FAMILIES)
shuffle(FAMILIES)

parallel = Parallel(n_jobs=12)
results = parallel(delayed(process_dgarchive_family)(family) for family in FAMILIES)
