# stdlib
import warnings
from pathlib import Path

# third party
import numpy as np
import pandas as pd
from joblib import Parallel, delayed
from sklearn.manifold import TSNE
from sklearn.preprocessing import MinMaxScaler

# dga_analysis absolute
from dga_analysis.datasets.dataset_alexa import DatasetAlexa
from dga_analysis.datasets.dataset_altered_benign import STRATEGIES, DatasetAltered
from dga_analysis.datasets.dataset_cisco import DatasetCisco
from dga_analysis.datasets.dataset_dgarchive import FAMILIES, DatasetDGArchive
from dga_analysis.datasets.dataset_synthetic_dga import FAMILIES as SYN_FAMILIES
from dga_analysis.datasets.dataset_synthetic_dga import DatasetSyntheticDGA
from dga_analysis.datasets.dataset_tranco import DatasetTranco
from dga_analysis.utils.serialization import dataframe_hash

parallel = Parallel(n_jobs=10)

warnings.filterwarnings("ignore")

SAMPLE_SIZE = 50000
only_2ld = True

FILTERED_COLS = [
    "domain-name-length",
    "contains-digits",
    "end-digit-edge-distance",
    "start-digit-edge-distance",
    "inverse-hamming-distance",
    "consonants-max-streak-length",
    "decimaldigits-max-streak-length",
    "hexadecimaldigits-max-streak-length",
    "primedigits-max-streak-length",
    "hyphens-max-streak-length",
    "vowels-max-streak-length",
    "syllable-count",
    "bits-entropy",
    "binary-matrix-rank-test",
    "longest-run-of-ones-test",
    "adjacent-duplicates-ratio",
    "alphabet-hyphen",
    "alphabet-0",
    "alphabet-1",
    "alphabet-2",
    "alphabet-3",
    "alphabet-4",
    "alphabet-5",
    "alphabet-6",
    "alphabet-7",
    "alphabet-8",
    "alphabet-9",
    "alphabet-a",
    "alphabet-b",
    "alphabet-c",
    "alphabet-d",
    "alphabet-e",
    "alphabet-f",
    "alphabet-g",
    "alphabet-h",
    "alphabet-i",
    "alphabet-j",
    "alphabet-k",
    "alphabet-l",
    "alphabet-m",
    "alphabet-n",
    "alphabet-o",
    "alphabet-p",
    "alphabet-q",
    "alphabet-r",
    "alphabet-s",
    "alphabet-t",
    "alphabet-u",
    "alphabet-v",
    "alphabet-w",
    "alphabet-x",
    "alphabet-y",
    "alphabet-z",
    "consonants-character-ratio",
    "decimaldigits-character-ratio",
    "hexadecimaldigits-character-ratio",
    "hyphens-character-ratio",
    "primedigits-character-ratio",
    "vowels-character-ratio",
    "underscore-character-ratio",
    "consecutive-consonant-ratio",
    "consecutive-digit-ratio",
    "suffix-digit-sum",
    "first-character-pair",
    "repeated-characters-ratio",
    "suffix-standard-deviation",
    "weighted-streaks",
    "1-gram-alphabet-diversity",
    "1-gram-alphabet-size",
    "1-gram-arithmetic-mean",
    "1-gram-harmonic-mean",
    "1-gram-kurtosis",
    "1-gram-lower-quartile",
    "1-gram-max",
    "1-gram-median",
    "1-gram-min",
    "1-gram-shannon-entropy",
    "1-gram-skewness",
    "1-gram-standard-deviation",
    "1-gram-upper-quartile",
    "2-gram-alphabet-diversity",
    "2-gram-alphabet-size",
    "2-gram-arithmetic-mean",
    "2-gram-harmonic-mean",
    "2-gram-kurtosis",
    "2-gram-lower-quartile",
    "2-gram-max",
    "2-gram-median",
    "2-gram-min",
    "2-gram-shannon-entropy",
    "2-gram-skewness",
    "2-gram-standard-deviation",
    "2-gram-upper-quartile",
]


dataset_benign = DatasetTranco(
    sample_size=SAMPLE_SIZE,
)
dataset_alexa = DatasetAlexa(
    sample_size=SAMPLE_SIZE,
)
dataset_cisco = DatasetCisco(
    sample_size=SAMPLE_SIZE,
)
X_benign, _ = dataset_benign.as_statistical(only_2ld=only_2ld)
X_benign = np.asarray(X_benign[FILTERED_COLS])
scaler = MinMaxScaler().fit(X_benign)
X_benign = scaler.transform(X_benign)


def preprocess_dataset(data):
    data = np.asarray(data[FILTERED_COLS])
    data = scaler.transform(data)
    return data


X_alexa, _ = dataset_alexa.as_statistical(only_2ld=only_2ld)
X_alexa = preprocess_dataset(X_alexa)

X_cisco, _ = dataset_cisco.as_statistical(only_2ld=only_2ld)
X_cisco = preprocess_dataset(X_cisco)


dataset_benign.raw_df(only_2ld=only_2ld)["domain"].value_counts()


WORKSPACE = Path("workspace")
WORKSPACE.mkdir(parents=True, exist_ok=True)


def load_dgarchive_family(family: str):
    dataset_mal = DatasetDGArchive(
        sample_size=SAMPLE_SIZE,
        max_source_size=SAMPLE_SIZE,
        families=[family],
    )

    X_mal, _ = dataset_mal.as_statistical(only_2ld=only_2ld)
    X_mal = preprocess_dataset(X_mal)

    return X_mal


def load_synthetic_family(family: str):
    dataset_mal = DatasetSyntheticDGA(
        sample_size=SAMPLE_SIZE,
        max_source_size=SAMPLE_SIZE,
        families=[family],
    )

    X_mal, _ = dataset_mal.as_statistical(only_2ld=only_2ld)
    X_mal = preprocess_dataset(X_mal)

    return X_mal


def load_all_dgarchive_families():
    dataset_mal = DatasetDGArchive(
        sample_size=SAMPLE_SIZE,
        max_source_size=SAMPLE_SIZE,
    )

    X_mal, _ = dataset_mal.as_statistical(only_2ld=only_2ld)
    X_mal = preprocess_dataset(X_mal)

    return X_mal


def load_altered_tranco(strategy: str):
    dataset_mal = DatasetAltered(
        sample_size=SAMPLE_SIZE,
        strategy=strategy,
    )

    X_mal, _ = dataset_mal.as_statistical(only_2ld=only_2ld)
    X_mal = preprocess_dataset(X_mal)

    return X_mal


def fit_tsne(data):
    data = pd.DataFrame(data)
    cache_file = WORKSPACE / f"tsne_cache_{dataframe_hash(data)}.bkp"
    if cache_file.exists():
        try:
            proj = pd.read_csv(cache_file)
            return np.asarray(proj)
        except BaseException:
            pass

    tsne = TSNE(n_components=2, random_state=0, init="random")
    proj = pd.DataFrame(tsne.fit_transform(data))
    proj.to_csv(cache_file, index=None)

    return np.asarray(proj)


def plot_tsne(
    left_data,
    left_label: str,
    right_data,
    right_label: str,
    right_bullet_alpha=0.5,
    right_bullet_size=2,
):
    fit_tsne(left_data)
    fit_tsne(right_data)


plot_tsne(
    X_benign,
    "Tranco",
    X_alexa,
    "Alexa",
)


plot_tsne(
    X_benign,
    "Tranco",
    X_cisco,
    "Cisco",
)


# ## Plot against all DGA families

X_mal = load_all_dgarchive_families()
plot_tsne(
    X_benign,
    "Tranco",
    X_mal,
    "DGArchive",
)


# dga_analysis absolute


def eval_dgarchive(family):
    try:
        X_mal = load_dgarchive_family(family)
        print(
            "family",
            family,
            len(X_mal),
        )
        plot_tsne(
            X_benign,
            "Benign: Tranco",
            X_mal,
            f"DGA: {family}",
        )
    except BaseException as e:
        print("family failed", family, e, flush=True)


results = parallel(delayed(eval_dgarchive)(family) for family in FAMILIES)


# ## Plot against all Synthetic DGA


def eval_synthetic(family):
    try:
        X_mal = load_synthetic_family(family)
        plot_tsne(
            X_benign,
            "Benign: Tranco",
            X_mal,
            f"DGA: {family}",
        )
    except BaseException:
        print("family failed", family, flush=True)


results = parallel(delayed(eval_synthetic)(family) for family in SYN_FAMILIES)


# ## Plot with Altered Tranco


def eval_altered(strategy):
    try:
        X_mal = load_altered_tranco(strategy)
        plot_tsne(
            X_benign,
            "Benign: Tranco",
            X_mal,
            f"DGA: {strategy}",
        )
    except BaseException:
        print("family failed", strategy, flush=True)


results = parallel(delayed(eval_altered)(strategy) for strategy in STRATEGIES)
