{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394cc8fe-0a8e-4e87-998c-9df0690ce8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# stdlib\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from tldextract import extract\n",
    "\n",
    "# dga_analysis absolute\n",
    "from dga_analysis.datasets.dataset_altered_benign import STRATEGIES, DatasetAltered\n",
    "from dga_analysis.datasets.dataset_dgarchive import FAMILIES as DGA_FAMILIES\n",
    "from dga_analysis.datasets.dataset_mixed import DatasetMixed\n",
    "from dga_analysis.datasets.dataset_synthetic_dga import FAMILIES as SYN_FAMILIES\n",
    "from dga_analysis.datasets.dataset_tranco import DatasetTranco\n",
    "from dga_analysis.detection.cnn import CNNClassifier\n",
    "from dga_analysis.detection.ji import JIClassifier\n",
    "from dga_analysis.detection.knn import KNNClassifier\n",
    "from dga_analysis.detection.lr import LinearClassifier\n",
    "from dga_analysis.detection.nn import NeuralNetClassifier\n",
    "from dga_analysis.detection.recurrent import (\n",
    "    GRUClassifier,\n",
    "    LSTMClassifier,\n",
    "    RecurrentClassifier,\n",
    "    RNNClassifier,\n",
    ")\n",
    "from dga_analysis.detection.rescnn import ResCNNClassifier\n",
    "from dga_analysis.detection.rf import RFClassifier\n",
    "from dga_analysis.detection.svm import SVMClassifier\n",
    "from dga_analysis.detection.transformer import TransformerClassifier\n",
    "from dga_analysis.detection.tree import DecisionTreeClassifier\n",
    "from dga_analysis.detection.xgb import XGBoostClassifier\n",
    "from dga_analysis.utils.evaluation import evaluate_classifier\n",
    "from dga_analysis.utils.features.examples import ALL\n",
    "from dga_analysis.utils.serialization import (\n",
    "    dataframe_hash,\n",
    "    load_from_file,\n",
    "    save_to_file,\n",
    ")\n",
    "\n",
    "SAMPLE_SIZE = 40000\n",
    "DGA_SUBSAMPLES = 20000\n",
    "WORKSPACE = Path(\"workspace\")\n",
    "WORKSPACE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MULTICLASS = False\n",
    "MODELS_2D = [\n",
    "    \"rf\",\n",
    "    \"lr\",\n",
    "    # \"svm\",\n",
    "    \"xgb\",\n",
    "    \"tree\",\n",
    "    \"nn\",\n",
    "]\n",
    "\n",
    "MODELS_3D = [\n",
    "    # \"rnn\",\n",
    "    # \"lstm\",\n",
    "    # \"gru\",\n",
    "    # \"transformer\",\n",
    "    # \"cnn\",\n",
    "    \"rescnn\",\n",
    "    # \"ji\",\n",
    "]\n",
    "\n",
    "TEST_DATA = DatasetTranco(sample_size=200000, shuffle=False)\n",
    "Xtest_raw, ytest = TEST_DATA.raw_np(only_2ld=True)\n",
    "Xtest_embs, ytest = TEST_DATA.as_embeddings(only_2ld=True)\n",
    "Xtest_stats, ytest = TEST_DATA.as_statistical(only_2ld=True)\n",
    "\n",
    "\n",
    "def load_model(model: str):\n",
    "    if model == \"rf\":\n",
    "        return RFClassifier()\n",
    "    elif model == \"lr\":\n",
    "        return LinearClassifier()\n",
    "    elif model == \"svm\":\n",
    "        return SVMClassifier()\n",
    "    elif model == \"xgb\":\n",
    "        return XGBoostClassifier()\n",
    "    elif model == \"tree\":\n",
    "        return DecisionTreeClassifier()\n",
    "    elif model == \"nn\":\n",
    "        return NeuralNetClassifier(\n",
    "            n_layers_hidden=2,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"cnn\":\n",
    "        return CNNClassifier(\n",
    "            n_units_emb=256,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"ji\":\n",
    "        return JIClassifier()\n",
    "    elif model == \"transformer\":\n",
    "        return TransformerClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"lstm\":\n",
    "        return LSTMClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"rnn\":\n",
    "        return RNNClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"gru\":\n",
    "        return GRUClassifier(\n",
    "            n_layers=2,\n",
    "            n_units_emb=200,\n",
    "            n_units_hidden=200,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    elif model == \"rescnn\":\n",
    "        return ResCNNClassifier(\n",
    "            n_units_emb=256,\n",
    "            dropout=0.1,\n",
    "            n_iter=1000,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplemented(model)\n",
    "\n",
    "\n",
    "def load_dgarchive_family(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"dgarchive\": 0.5},\n",
    "        multiclass=MULTICLASS,\n",
    "        dga_families=[family],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def benchmark_family_2d(family: str, scenario: str, X, y):\n",
    "    if scenario == \"raw\":\n",
    "        models = MODELS_3D\n",
    "        Xtest = Xtest_raw\n",
    "    elif scenario == \"embs\":\n",
    "        models = MODELS_2D\n",
    "        Xtest = Xtest_embs\n",
    "    else:\n",
    "        models = MODELS_2D\n",
    "        Xtest = Xtest_stats\n",
    "\n",
    "    X = np.asarray(X)\n",
    "\n",
    "    data_hash = dataframe_hash(pd.DataFrame(X))\n",
    "\n",
    "    best_score = None\n",
    "    min_fps = 9999999999999\n",
    "    for model_name in models:\n",
    "        cache_file = WORKSPACE / f\"benchmarks_btopn_bias_{model_name}_{data_hash}.bkp\"\n",
    "        if cache_file.exists():\n",
    "            scores = load_from_file(cache_file)\n",
    "            if np.sum(scores) < min_fps:\n",
    "                best_score = scores\n",
    "                min_fps = np.sum(scores)\n",
    "            # print(\n",
    "            #     \"cached\",\n",
    "            #     family,\n",
    "            #     model_name,\n",
    "            #     np.sum(scores),\n",
    "            #     flush=True,\n",
    "            # )\n",
    "    return best_score\n",
    "\n",
    "\n",
    "def benchmark_dgarchive_2d(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    X, y = load_dgarchive_family(\n",
    "        family,\n",
    "        scenario=scenario,\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    return benchmark_family_2d(family, scenario, X, y)\n",
    "\n",
    "\n",
    "def load_synthetic_family(\n",
    "    family: str,\n",
    "    scenario: str = \"stats\",\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 10000,\n",
    "):  # stats, embs, raw\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"synthetic_dga\": 0.5},\n",
    "        multiclass=MULTICLASS,\n",
    "        dga_families=[family],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True, max_length=100)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def benchmark_synthetic(\n",
    "    family: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 10000,\n",
    "):\n",
    "    X, y = load_synthetic_family(\n",
    "        family,\n",
    "        scenario=scenario,\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    return benchmark_family_2d(family, scenario, X, y)\n",
    "\n",
    "\n",
    "def load_altered_family(\n",
    "    strategy: str, scenario: str, max_benign_source: int, max_dga_source: int\n",
    "):\n",
    "    dataset = DatasetMixed(\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        sources={\"tranco\": 0.5, \"altered_benign\": 0.5},\n",
    "        dga_families=[strategy],\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    if scenario == \"stats\":\n",
    "        return dataset.as_statistical(only_2ld=True)\n",
    "    elif scenario == \"embs\":\n",
    "        return dataset.as_embeddings(only_2ld=True)\n",
    "    else:\n",
    "        return dataset.raw(only_2ld=True)\n",
    "\n",
    "\n",
    "def benchmark_altered_2d(\n",
    "    strategy: str,\n",
    "    scenario: str,\n",
    "    max_benign_source: int = 100000,\n",
    "    max_dga_source: int = 100000,\n",
    "):\n",
    "    X, y = load_altered_family(\n",
    "        strategy,\n",
    "        scenario=scenario,\n",
    "        max_benign_source=max_benign_source,\n",
    "        max_dga_source=max_dga_source,\n",
    "    )\n",
    "    return benchmark_family_2d(strategy, scenario, X, y)\n",
    "\n",
    "\n",
    "BENIGN_SUBSAMPLES = [100, 1000, 10000, 20000, 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e1a29-5d77-428d-bd5c-bf2617720e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cache_file = Path(\"results/benchmark_benign_topn_bias.bkp\")\n",
    "\n",
    "if results_cache_file.exists():\n",
    "    results = load_from_file(results_cache_file)\n",
    "else:\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9153743-466b-4cdf-9619-2ff9ecde06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = [\"embs\", \"raw\"]\n",
    "\n",
    "\n",
    "def _extract_scores(families, cbk, results):\n",
    "    for benign_size in BENIGN_SUBSAMPLES:\n",
    "        if benign_size not in results:\n",
    "            results[benign_size] = {}\n",
    "        for family in families:\n",
    "            if family in results[benign_size]:\n",
    "                continue\n",
    "            best_score = None\n",
    "            min_fps = 999999999999999\n",
    "            for scenario in SCENARIOS:\n",
    "                local_scores = cbk(\n",
    "                    family,\n",
    "                    scenario=scenario,\n",
    "                    max_benign_source=benign_size,\n",
    "                    max_dga_source=DGA_SUBSAMPLES,\n",
    "                )\n",
    "                if local_scores is None:\n",
    "                    continue\n",
    "                if np.sum(local_scores) < min_fps:\n",
    "                    best_score = local_scores\n",
    "                    min_fps = np.sum(local_scores)\n",
    "            if best_score is None:\n",
    "                continue\n",
    "            results[benign_size][family] = best_score\n",
    "            print(benign_size, family, min_fps)\n",
    "    return results\n",
    "\n",
    "\n",
    "results = _extract_scores(STRATEGIES, benchmark_altered_2d, results)\n",
    "results = _extract_scores(SYN_FAMILIES, benchmark_synthetic, results)\n",
    "results = _extract_scores(DGA_FAMILIES, benchmark_dgarchive_2d, results)\n",
    "\n",
    "save_to_file(results_cache_file, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd974ec5-ce98-4d3d-b384-f53e8748a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_from_file(results_cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee8aa7-0065-4d03-872c-9c8cb335a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bd2f0-4a1b-451d-9938-a5045b5d7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSET = 50000\n",
    "\n",
    "pretty_results = []\n",
    "for cnt in BENIGN_SUBSAMPLES:\n",
    "    for family in results[cnt]:\n",
    "        fps = np.sum(results[cnt][family][OFFSET:])\n",
    "        total = len(results[cnt][family][OFFSET:])\n",
    "\n",
    "        pretty_results.append([cnt, family, fps, fps / total])\n",
    "\n",
    "\n",
    "pretty_results = pd.DataFrame(\n",
    "    pretty_results, columns=[\"Train Size\", \"Family\", \"FP Count\", \"FP Ratio\"]\n",
    ")\n",
    "\n",
    "pretty_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b895b-47c9-4df9-b19a-f930770b0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_results.sort_values(\"FP Ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce03f0-1648-4fc8-86bc-73d496e64bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGRAMS = Path(\"diagrams\")\n",
    "DIAGRAMS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# third party\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# libraries & dataset\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "FONT_SIZE = 18\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "custom_colors = prop_cycle.by_key()[\"color\"]\n",
    "custom_colors.extend(\n",
    "    [\n",
    "        \"#c5b0d5\",\n",
    "        \"#ffc500\",\n",
    "        \"#700548\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def format_func(value, tick_number):\n",
    "    return f\"{value:.1f}\"\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7, 3))\n",
    "ax = plt.gca()\n",
    "\n",
    "hue_palette = [\n",
    "    custom_colors[0],\n",
    "    custom_colors[1],\n",
    "    custom_colors[3],\n",
    "    custom_colors[11],\n",
    "]\n",
    "hatches = [\"////\", \"\\\\\\\\\\\\\\\\\\\\\", \"|||||\", \"xxxx\", \"ooo\"]\n",
    "\n",
    "bp = sns.boxplot(\n",
    "    x=pretty_results[\"Train Size\"],\n",
    "    y=pretty_results[\"FP Ratio\"],\n",
    "    # hue = pretty_results[\"Train Size\"],\n",
    "    # palette=hue_palette,\n",
    "    color=\"white\",  # custom_colors[1],\n",
    "    linecolor=custom_colors[1],\n",
    "    fliersize=7,\n",
    "    # flierprops={ \"marker\": \"o\",  \"markeredgecolor\": custom_colors[3], \"color\": \"white\", \"markerfacecolor\": custom_colors[3], \"alpha\": 0.2},\n",
    "    boxprops={\"facecolor\": \"none\", \"linewidth\": 2, \"alpha\": 0.9, \"hatch\": \"//////\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"solid\"},\n",
    "    meanline=True,\n",
    "    showmeans=True,\n",
    "    meanprops={\"color\": \"black\", \"linewidth\": 1, \"linestyle\": \"dashdot\"},\n",
    ")\n",
    "for i, bar in enumerate(bp.patches):\n",
    "    if not isinstance(bar, matplotlib.patches.PathPatch):\n",
    "        continue\n",
    "    bar.set_hatch(hatches[int(i)])\n",
    "    # bar.set_edgecolor(hue_palette[int(i)])\n",
    "\n",
    "\n",
    "# ax0.set_xlabel(\"Performance Metric\", fontsize = FONT_SIZE)\n",
    "fig.text(0.55, -0.05, \"Training Benign Dataset Size\", fontsize=FONT_SIZE, ha=\"center\")\n",
    "ax.set_ylabel(\"False-Positive Ratio\", fontsize=FONT_SIZE)\n",
    "ax.set_xlabel(None)\n",
    "\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "ax.tick_params(axis=\"both\", which=\"minor\", labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "figname = \"benchmarks_topn_benign_bias\"\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "plt.savefig(DIAGRAMS / f\"{figname}.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a600605-455f-44d7-a11e-2af83782b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt in [50000]:\n",
    "    for family in results[cnt]:\n",
    "        fps = np.sum(results[cnt][family][OFFSET:])\n",
    "        total = len(results[cnt][family][OFFSET:])\n",
    "        test_values = Xtest_raw[OFFSET:]\n",
    "\n",
    "        indexes = results[cnt][family][OFFSET:].astype(bool)\n",
    "        values = pd.Series(test_values)\n",
    "        print(family, fps, values[indexes].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e797c46-45eb-4726-812c-59657de4855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_results[pretty_results[\"Train Size\"] == 50000].sort_values(\"FP Ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe2b9a-d88f-494c-ac32-c821f0779c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dga",
   "language": "python",
   "name": "dga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
